{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow intro\n",
    "\n",
    "This tutorial shows the basic usage of tensorflow to train neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "Read data and convert them to numerical inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=20000, n_features=8, n_informative=5, \n",
    "                           n_redundant=0, n_classes=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (12800, 8), target_ratio: 0.502\n",
      "test size: (4000, 8), target_ratio: 0.501\n",
      "dev size: (3200, 8), target_ratio: 0.502\n"
     ]
    }
   ],
   "source": [
    "print('train size: {}, target_ratio: {:.3f}'.format(X_train.shape, np.mean(y_train)))\n",
    "print('test size: {}, target_ratio: {:.3f}'.format(X_test.shape, np.mean(y_test)))\n",
    "print('dev size: {}, target_ratio: {:.3f}'.format(X_dev.shape, np.mean(y_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple model with tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very useful documentations with many examples and detailed explanation of everything you might need:\n",
    " - https://www.tensorflow.org/api_docs/python/tf/keras/\n",
    " - https://keras.io/api/\n",
    "\n",
    "Contain everything about:\n",
    "  - Model building: Activations, Losses, Optimizers, Regularization\n",
    "  - Data processing\n",
    "  - Pretrained models and datasets\n",
    "  - Automatic differentiation\n",
    "  - ...\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model speficication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "three APIs for building the model\n",
    "   - sequential - easy to code, but less flexible - we will use it sometimes\n",
    "   - functional - flexible and still easy to code - we will use it the most\n",
    "   - model subclassing - rather complicated and not very much used - we will skip it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.tensorflow.org/guide/keras/sequential_model)\n",
    "\n",
    "Easy to code but not appropriate when:\n",
    "\n",
    "- Your model has multiple inputs or multiple outputs\n",
    "- Any of your layers has multiple inputs or multiple outputs\n",
    "- You need to do layer sharing\n",
    "- You want non-linear topology (e.g. a residual connection, a multi-branch model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Specification A)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer([X_train.shape[1],]), # Create input layer with 'input data' neurons\n",
    "    tf.keras.layers.Dense(10, activation=\"relu\"), # Create hidden layer with 10 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"), # Create output layer with one neuron and sigmoid activation\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Specification B)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.tensorflow.org/guide/keras/functional)\n",
    "\n",
    "The Keras functional API is a way to create models that are more flexible than the tf.keras.Sequential API. The functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n",
    "\n",
    "The main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
    "\n",
    "hidden = tf.keras.layers.Dense(10)(inputs)\n",
    "hidden = tf.keras.activations.relu(hidden)\n",
    "hidden = tf.keras.layers.Dense(1)(hidden)\n",
    "outputs = tf.keras.activations.sigmoid(hidden)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu (TensorFlow [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Sigmoid (TensorF [(None, 1)]               0         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with selected optimizer, loss and metrics\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam(), # Several other possibilities for optimizers \n",
    "        loss=tf.losses.BinaryCrossentropy(), # Select the proper loss for the task\n",
    "        metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.BinaryAccuracy()], # Select the proper metrics for the task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Bias of the last layers:\n",
      "[0.]\n",
      "\n",
      ">>> Kernel of the last layers:\n",
      "[[ 0.04851639]\n",
      " [-0.24508768]\n",
      " [-0.13187832]\n",
      " [ 0.05884331]\n",
      " [-0.15282243]\n",
      " [-0.3866087 ]\n",
      " [ 0.6848112 ]\n",
      " [-0.22949755]\n",
      " [-0.09657723]\n",
      " [-0.64680386]]\n",
      "\n",
      ">>> Bias of the first layers:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      ">>> Kernel of the first layers:\n",
      "[[-0.49263224 -0.32091686  0.23436737 -0.01964736  0.38018882  0.33966905\n",
      "  -0.12686235  0.47103775 -0.24198651 -0.12971807]\n",
      " [ 0.15010089 -0.27177432  0.37964827 -0.37813812  0.45467758  0.00761402\n",
      "  -0.17108136 -0.09188083  0.00311667  0.01995319]\n",
      " [ 0.21115613  0.556085    0.523522   -0.42312437  0.29241908  0.17406416\n",
      "   0.01183522 -0.32265553  0.22161222 -0.02221262]\n",
      " [ 0.3853857   0.13021207  0.11804235 -0.05382901  0.42697048 -0.35721403\n",
      "  -0.07440573  0.1814974   0.37874871 -0.18781891]\n",
      " [ 0.40240794  0.05259258  0.22057366 -0.03655571 -0.22361258  0.27079827\n",
      "  -0.35875314  0.49570286  0.02230388  0.5181092 ]\n",
      " [ 0.43708265 -0.05469453 -0.14172357 -0.35890868  0.17780411  0.4027698\n",
      "   0.15361619 -0.26355767  0.03466672 -0.22678295]\n",
      " [-0.08736932  0.4160388  -0.5260618  -0.33806336  0.07182413 -0.11060908\n",
      "   0.15518683 -0.3985062  -0.08956292 -0.13769934]\n",
      " [-0.12201923 -0.3492226  -0.36904585 -0.51345     0.53926194 -0.2605624\n",
      "  -0.51972497 -0.12704763  0.5245446  -0.50983876]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n>>> Bias of the last layers:')\n",
    "print(model.layers[3].weights[1].numpy())\n",
    "\n",
    "print('\\n>>> Kernel of the last layers:')\n",
    "print(model.layers[3].weights[0].numpy())\n",
    "\n",
    "print('\\n>>> Bias of the first layers:')\n",
    "print(model.layers[1].weights[1].numpy())\n",
    "\n",
    "print('\\n>>> Kernel of the first layers:')\n",
    "print(model.layers[1].weights[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 0s 756us/step - loss: 0.5614 - auc: 0.8051 - binary_accuracy: 0.7152\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 642us/step - loss: 0.4301 - auc: 0.8970 - binary_accuracy: 0.8218\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 708us/step - loss: 0.3773 - auc: 0.9196 - binary_accuracy: 0.8535\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 643us/step - loss: 0.3431 - auc: 0.9329 - binary_accuracy: 0.8712\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 643us/step - loss: 0.3200 - auc: 0.9405 - binary_accuracy: 0.8810\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 788us/step - loss: 0.3044 - auc: 0.9461 - binary_accuracy: 0.8866\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 808us/step - loss: 0.2942 - auc: 0.9487 - binary_accuracy: 0.8898\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 643us/step - loss: 0.2877 - auc: 0.9505 - binary_accuracy: 0.8931\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 638us/step - loss: 0.2826 - auc: 0.9521 - binary_accuracy: 0.8955\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 702us/step - loss: 0.2784 - auc: 0.9533 - binary_accuracy: 0.8967\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 643us/step - loss: 0.2747 - auc: 0.9544 - binary_accuracy: 0.8982\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 643us/step - loss: 0.2713 - auc: 0.9557 - binary_accuracy: 0.9009\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 628us/step - loss: 0.2681 - auc: 0.9567 - binary_accuracy: 0.9026\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 628us/step - loss: 0.2654 - auc: 0.9576 - binary_accuracy: 0.9038\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 658us/step - loss: 0.2625 - auc: 0.9587 - binary_accuracy: 0.9046\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 623us/step - loss: 0.2597 - auc: 0.9594 - binary_accuracy: 0.9059\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 628us/step - loss: 0.2573 - auc: 0.9604 - binary_accuracy: 0.9057\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 628us/step - loss: 0.2553 - auc: 0.9610 - binary_accuracy: 0.9063\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2525 - auc: 0.9620 - binary_accuracy: 0.9079\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 663us/step - loss: 0.2510 - auc: 0.9624 - binary_accuracy: 0.9089\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 649us/step - loss: 0.2491 - auc: 0.9630 - binary_accuracy: 0.9094\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2476 - auc: 0.9633 - binary_accuracy: 0.9102\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 623us/step - loss: 0.2462 - auc: 0.9638 - binary_accuracy: 0.9097\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 628us/step - loss: 0.2449 - auc: 0.9641 - binary_accuracy: 0.9116\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 628us/step - loss: 0.2438 - auc: 0.9644 - binary_accuracy: 0.9107\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2424 - auc: 0.9649 - binary_accuracy: 0.9125\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 648us/step - loss: 0.2416 - auc: 0.9651 - binary_accuracy: 0.9117\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2406 - auc: 0.9653 - binary_accuracy: 0.9121\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2398 - auc: 0.9655 - binary_accuracy: 0.9131\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 636us/step - loss: 0.2391 - auc: 0.9656 - binary_accuracy: 0.9137\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 636us/step - loss: 0.2384 - auc: 0.9659 - binary_accuracy: 0.9128\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 638us/step - loss: 0.2377 - auc: 0.9661 - binary_accuracy: 0.9139\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 637us/step - loss: 0.2371 - auc: 0.9662 - binary_accuracy: 0.9134\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 623us/step - loss: 0.2367 - auc: 0.9664 - binary_accuracy: 0.9129\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 628us/step - loss: 0.2358 - auc: 0.9666 - binary_accuracy: 0.9136\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 638us/step - loss: 0.2351 - auc: 0.9668 - binary_accuracy: 0.9124\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2348 - auc: 0.9669 - binary_accuracy: 0.9141\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 623us/step - loss: 0.2345 - auc: 0.9670 - binary_accuracy: 0.9132\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2337 - auc: 0.9672 - binary_accuracy: 0.9133\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 638us/step - loss: 0.2335 - auc: 0.9672 - binary_accuracy: 0.9134\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2328 - auc: 0.9676 - binary_accuracy: 0.9137\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 623us/step - loss: 0.2324 - auc: 0.9676 - binary_accuracy: 0.9148\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.2318 - auc: 0.9678 - binary_accuracy: 0.9156\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 643us/step - loss: 0.2314 - auc: 0.9678 - binary_accuracy: 0.9142\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2311 - auc: 0.9680 - binary_accuracy: 0.9147\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 713us/step - loss: 0.2306 - auc: 0.9680 - binary_accuracy: 0.9155\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2302 - auc: 0.9681 - binary_accuracy: 0.9149\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2297 - auc: 0.9683 - binary_accuracy: 0.9146\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 928us/step - loss: 0.2295 - auc: 0.9683 - binary_accuracy: 0.9143\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2321 - auc: 0.9675 - binary_accuracy: 0.914 - 0s 701us/step - loss: 0.2290 - auc: 0.9685 - binary_accuracy: 0.9149\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 692us/step - loss: 0.2287 - auc: 0.9685 - binary_accuracy: 0.9141\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 646us/step - loss: 0.2282 - auc: 0.9687 - binary_accuracy: 0.9154\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 632us/step - loss: 0.2277 - auc: 0.9689 - binary_accuracy: 0.9162\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 635us/step - loss: 0.2277 - auc: 0.9688 - binary_accuracy: 0.9157\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 733us/step - loss: 0.2274 - auc: 0.9689 - binary_accuracy: 0.9145\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 803us/step - loss: 0.2269 - auc: 0.9691 - binary_accuracy: 0.9149\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 863us/step - loss: 0.2267 - auc: 0.9691 - binary_accuracy: 0.9155\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 698us/step - loss: 0.2264 - auc: 0.9692 - binary_accuracy: 0.9157\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 708us/step - loss: 0.2259 - auc: 0.9693 - binary_accuracy: 0.9159\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 942us/step - loss: 0.2255 - auc: 0.9695 - binary_accuracy: 0.9155\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 649us/step - loss: 0.2253 - auc: 0.9695 - binary_accuracy: 0.9158\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 741us/step - loss: 0.2251 - auc: 0.9696 - binary_accuracy: 0.9157\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 628us/step - loss: 0.2247 - auc: 0.9696 - binary_accuracy: 0.9168\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 646us/step - loss: 0.2243 - auc: 0.9699 - binary_accuracy: 0.9165\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 636us/step - loss: 0.2242 - auc: 0.9699 - binary_accuracy: 0.9163\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 643us/step - loss: 0.2236 - auc: 0.9700 - binary_accuracy: 0.9166\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2235 - auc: 0.9700 - binary_accuracy: 0.9163\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 643us/step - loss: 0.2229 - auc: 0.9702 - binary_accuracy: 0.9170\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2225 - auc: 0.9703 - binary_accuracy: 0.9151\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 628us/step - loss: 0.2222 - auc: 0.9704 - binary_accuracy: 0.9164\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 638us/step - loss: 0.2218 - auc: 0.9706 - binary_accuracy: 0.9171\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 638us/step - loss: 0.2216 - auc: 0.9706 - binary_accuracy: 0.9173\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2209 - auc: 0.9708 - binary_accuracy: 0.9161\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 631us/step - loss: 0.2207 - auc: 0.9709 - binary_accuracy: 0.9166\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2202 - auc: 0.9710 - binary_accuracy: 0.9170\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 758us/step - loss: 0.2202 - auc: 0.9710 - binary_accuracy: 0.9166\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 673us/step - loss: 0.2198 - auc: 0.9711 - binary_accuracy: 0.9170\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 663us/step - loss: 0.2193 - auc: 0.9713 - binary_accuracy: 0.9167\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 653us/step - loss: 0.2190 - auc: 0.9713 - binary_accuracy: 0.9175\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2188 - auc: 0.9715 - binary_accuracy: 0.9161\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 638us/step - loss: 0.2187 - auc: 0.9714 - binary_accuracy: 0.9170\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2173 - auc: 0.9713 - binary_accuracy: 0.916 - 0s 688us/step - loss: 0.2179 - auc: 0.9718 - binary_accuracy: 0.9180\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 823us/step - loss: 0.2176 - auc: 0.9718 - binary_accuracy: 0.9178\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 696us/step - loss: 0.2172 - auc: 0.9719 - binary_accuracy: 0.9173\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 668us/step - loss: 0.2169 - auc: 0.9720 - binary_accuracy: 0.9170\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2167 - auc: 0.9722 - binary_accuracy: 0.9162\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 638us/step - loss: 0.2161 - auc: 0.9722 - binary_accuracy: 0.9181\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 698us/step - loss: 0.2159 - auc: 0.9723 - binary_accuracy: 0.9164\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.2153 - auc: 0.9724 - binary_accuracy: 0.9185\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 653us/step - loss: 0.2146 - auc: 0.9727 - binary_accuracy: 0.9189\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 633us/step - loss: 0.2143 - auc: 0.9728 - binary_accuracy: 0.9201\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 653us/step - loss: 0.2139 - auc: 0.9729 - binary_accuracy: 0.9187\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 998us/step - loss: 0.2135 - auc: 0.9730 - binary_accuracy: 0.9191\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 708us/step - loss: 0.2130 - auc: 0.9733 - binary_accuracy: 0.9191\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 688us/step - loss: 0.2126 - auc: 0.9733 - binary_accuracy: 0.9186\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 841us/step - loss: 0.2122 - auc: 0.9733 - binary_accuracy: 0.9181\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 698us/step - loss: 0.2117 - auc: 0.9737 - binary_accuracy: 0.9189\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 681us/step - loss: 0.2114 - auc: 0.9737 - binary_accuracy: 0.9196\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 653us/step - loss: 0.2108 - auc: 0.9737 - binary_accuracy: 0.9196\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 653us/step - loss: 0.2108 - auc: 0.9739 - binary_accuracy: 0.9192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ecfc4a01c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model with default setting\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 654us/step - loss: 0.2349 - auc: 0.9681 - binary_accuracy: 0.9120\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and predict for the test data\n",
    "model.evaluate(X_test, y_test)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 0.49\n",
      "0 - 0.34\n",
      "0 - 0.26\n",
      "1 - 1.00\n",
      "0 - 0.00\n",
      "0 - 0.00\n",
      "1 - 0.97\n",
      "0 - 0.06\n",
      "1 - 0.93\n",
      "1 - 1.00\n"
     ]
    }
   ],
   "source": [
    "for pred, true in zip(test_pred, y_test[0:10]):\n",
    "    print('{} - {:.2f}'.format(true, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add early stopping and regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RegularizedModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Relu_1 (TensorFl [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Sigmoid_1 (Tenso [(None, 1)]               0         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "\n",
    "# Hidden layer with regularization and ReLU\n",
    "hidden = tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.l2(0.001))(inputs)\n",
    "hidden = tf.keras.activations.relu(hidden)\n",
    "\n",
    "# Output layer with regularization and sigmoid\n",
    "outputs = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.001))(hidden)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='RegularizedModel')\n",
    "\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam(),\n",
    "        loss=tf.losses.BinaryCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "349/400 [=========================>....] - ETA: 0s - loss: 0.5904 - auc_1: 0.7594 - binary_accuracy: 0.6811WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.5726 - auc_1: 0.7799 - binary_accuracy: 0.6976 - val_loss: 0.4372 - val_auc_1: 0.9073 - val_binary_accuracy: 0.8169\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 0s 850us/step - loss: 0.3920 - auc_1: 0.9237 - binary_accuracy: 0.8449 - val_loss: 0.3556 - val_auc_1: 0.9353 - val_binary_accuracy: 0.8628\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 0s 757us/step - loss: 0.3404 - auc_1: 0.9411 - binary_accuracy: 0.8752 - val_loss: 0.3253 - val_auc_1: 0.9448 - val_binary_accuracy: 0.8803\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 0s 758us/step - loss: 0.3167 - auc_1: 0.9484 - binary_accuracy: 0.8884 - val_loss: 0.3086 - val_auc_1: 0.9504 - val_binary_accuracy: 0.8872\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 0s 755us/step - loss: 0.3019 - auc_1: 0.9531 - binary_accuracy: 0.8960 - val_loss: 0.2962 - val_auc_1: 0.9545 - val_binary_accuracy: 0.8969\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 0s 755us/step - loss: 0.2909 - auc_1: 0.9567 - binary_accuracy: 0.9013 - val_loss: 0.2880 - val_auc_1: 0.9573 - val_binary_accuracy: 0.8984\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 0s 755us/step - loss: 0.2828 - auc_1: 0.9593 - binary_accuracy: 0.9052 - val_loss: 0.2819 - val_auc_1: 0.9595 - val_binary_accuracy: 0.8988\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 0s 748us/step - loss: 0.2766 - auc_1: 0.9614 - binary_accuracy: 0.9082 - val_loss: 0.2770 - val_auc_1: 0.9610 - val_binary_accuracy: 0.9038\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 0s 754us/step - loss: 0.2721 - auc_1: 0.9628 - binary_accuracy: 0.9089 - val_loss: 0.2734 - val_auc_1: 0.9620 - val_binary_accuracy: 0.9034\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 0s 815us/step - loss: 0.2685 - auc_1: 0.9638 - binary_accuracy: 0.9102 - val_loss: 0.2688 - val_auc_1: 0.9638 - val_binary_accuracy: 0.9041\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2652 - auc_1: 0.9650 - binary_accuracy: 0.9125 - val_loss: 0.2658 - val_auc_1: 0.9649 - val_binary_accuracy: 0.9069\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 0s 853us/step - loss: 0.2624 - auc_1: 0.9659 - binary_accuracy: 0.9123 - val_loss: 0.2633 - val_auc_1: 0.9659 - val_binary_accuracy: 0.9081\n",
      "Epoch 13/200\n",
      "400/400 [==============================] - 0s 775us/step - loss: 0.2599 - auc_1: 0.9668 - binary_accuracy: 0.9123 - val_loss: 0.2611 - val_auc_1: 0.9671 - val_binary_accuracy: 0.9053\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 0s 979us/step - loss: 0.2575 - auc_1: 0.9677 - binary_accuracy: 0.9133 - val_loss: 0.2580 - val_auc_1: 0.9677 - val_binary_accuracy: 0.9094\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 0s 748us/step - loss: 0.2556 - auc_1: 0.9682 - binary_accuracy: 0.9137 - val_loss: 0.2559 - val_auc_1: 0.9685 - val_binary_accuracy: 0.9103\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 0s 726us/step - loss: 0.2535 - auc_1: 0.9690 - binary_accuracy: 0.9152 - val_loss: 0.2552 - val_auc_1: 0.9688 - val_binary_accuracy: 0.9109\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 0s 718us/step - loss: 0.2524 - auc_1: 0.9694 - binary_accuracy: 0.9159 - val_loss: 0.2541 - val_auc_1: 0.9696 - val_binary_accuracy: 0.9106\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 0s 714us/step - loss: 0.2513 - auc_1: 0.9699 - binary_accuracy: 0.9163 - val_loss: 0.2529 - val_auc_1: 0.9699 - val_binary_accuracy: 0.9106\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 0s 719us/step - loss: 0.2500 - auc_1: 0.9702 - binary_accuracy: 0.9164 - val_loss: 0.2528 - val_auc_1: 0.9702 - val_binary_accuracy: 0.9112\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 0s 711us/step - loss: 0.2493 - auc_1: 0.9704 - binary_accuracy: 0.9159 - val_loss: 0.2514 - val_auc_1: 0.9706 - val_binary_accuracy: 0.9112\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2485 - auc_1: 0.9708 - binary_accuracy: 0.9169 - val_loss: 0.2512 - val_auc_1: 0.9707 - val_binary_accuracy: 0.9137\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 0s 720us/step - loss: 0.2479 - auc_1: 0.9710 - binary_accuracy: 0.9169 - val_loss: 0.2506 - val_auc_1: 0.9709 - val_binary_accuracy: 0.9134\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 0s 853us/step - loss: 0.2471 - auc_1: 0.9712 - binary_accuracy: 0.9184 - val_loss: 0.2505 - val_auc_1: 0.9710 - val_binary_accuracy: 0.9131\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 0s 788us/step - loss: 0.2468 - auc_1: 0.9713 - binary_accuracy: 0.9177 - val_loss: 0.2505 - val_auc_1: 0.9712 - val_binary_accuracy: 0.9134\n",
      "Epoch 25/200\n",
      "400/400 [==============================] - 0s 733us/step - loss: 0.2463 - auc_1: 0.9715 - binary_accuracy: 0.9186 - val_loss: 0.2498 - val_auc_1: 0.9713 - val_binary_accuracy: 0.9125\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 0s 758us/step - loss: 0.2458 - auc_1: 0.9718 - binary_accuracy: 0.9191 - val_loss: 0.2495 - val_auc_1: 0.9714 - val_binary_accuracy: 0.9141\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 0s 928us/step - loss: 0.2454 - auc_1: 0.9718 - binary_accuracy: 0.9181 - val_loss: 0.2489 - val_auc_1: 0.9717 - val_binary_accuracy: 0.9134\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 0s 858us/step - loss: 0.2450 - auc_1: 0.9720 - binary_accuracy: 0.9187 - val_loss: 0.2498 - val_auc_1: 0.9715 - val_binary_accuracy: 0.9134\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 0s 809us/step - loss: 0.2449 - auc_1: 0.9720 - binary_accuracy: 0.9188 - val_loss: 0.2496 - val_auc_1: 0.9717 - val_binary_accuracy: 0.9128\n",
      "Epoch 30/200\n",
      "400/400 [==============================] - 0s 800us/step - loss: 0.2446 - auc_1: 0.9722 - binary_accuracy: 0.9187 - val_loss: 0.2487 - val_auc_1: 0.9719 - val_binary_accuracy: 0.9137\n",
      "Epoch 31/200\n",
      "400/400 [==============================] - 0s 925us/step - loss: 0.2442 - auc_1: 0.9723 - binary_accuracy: 0.9191 - val_loss: 0.2490 - val_auc_1: 0.9716 - val_binary_accuracy: 0.9134\n",
      "Epoch 32/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2440 - auc_1: 0.9724 - binary_accuracy: 0.9203 - val_loss: 0.2488 - val_auc_1: 0.9718 - val_binary_accuracy: 0.9137\n",
      "Epoch 33/200\n",
      "400/400 [==============================] - 0s 745us/step - loss: 0.2439 - auc_1: 0.9725 - binary_accuracy: 0.9192 - val_loss: 0.2492 - val_auc_1: 0.9718 - val_binary_accuracy: 0.9131\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - 0s 966us/step - loss: 0.2436 - auc_1: 0.9725 - binary_accuracy: 0.9190 - val_loss: 0.2494 - val_auc_1: 0.9721 - val_binary_accuracy: 0.9128\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - 0s 810us/step - loss: 0.2436 - auc_1: 0.9726 - binary_accuracy: 0.9197 - val_loss: 0.2485 - val_auc_1: 0.9719 - val_binary_accuracy: 0.9137\n",
      "Epoch 36/200\n",
      "400/400 [==============================] - 0s 805us/step - loss: 0.2432 - auc_1: 0.9727 - binary_accuracy: 0.9198 - val_loss: 0.2484 - val_auc_1: 0.9719 - val_binary_accuracy: 0.9150\n",
      "Epoch 37/200\n",
      "400/400 [==============================] - 0s 746us/step - loss: 0.2428 - auc_1: 0.9728 - binary_accuracy: 0.9197 - val_loss: 0.2486 - val_auc_1: 0.9721 - val_binary_accuracy: 0.9150\n",
      "Epoch 38/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2427 - auc_1: 0.9730 - binary_accuracy: 0.9211 - val_loss: 0.2474 - val_auc_1: 0.9722 - val_binary_accuracy: 0.9150\n",
      "Epoch 39/200\n",
      "400/400 [==============================] - 0s 853us/step - loss: 0.2426 - auc_1: 0.9731 - binary_accuracy: 0.9212 - val_loss: 0.2478 - val_auc_1: 0.9721 - val_binary_accuracy: 0.9159\n",
      "Epoch 40/200\n",
      "400/400 [==============================] - 0s 770us/step - loss: 0.2425 - auc_1: 0.9730 - binary_accuracy: 0.9192 - val_loss: 0.2482 - val_auc_1: 0.9723 - val_binary_accuracy: 0.9134\n",
      "Epoch 41/200\n",
      "400/400 [==============================] - 0s 787us/step - loss: 0.2423 - auc_1: 0.9732 - binary_accuracy: 0.9195 - val_loss: 0.2473 - val_auc_1: 0.9725 - val_binary_accuracy: 0.9150\n",
      "Epoch 42/200\n",
      "400/400 [==============================] - 0s 760us/step - loss: 0.2421 - auc_1: 0.9732 - binary_accuracy: 0.9199 - val_loss: 0.2473 - val_auc_1: 0.9725 - val_binary_accuracy: 0.9150\n",
      "Epoch 43/200\n",
      "400/400 [==============================] - 0s 755us/step - loss: 0.2416 - auc_1: 0.9735 - binary_accuracy: 0.9202 - val_loss: 0.2474 - val_auc_1: 0.9728 - val_binary_accuracy: 0.9147\n",
      "Epoch 44/200\n",
      "400/400 [==============================] - 0s 763us/step - loss: 0.2414 - auc_1: 0.9736 - binary_accuracy: 0.9209 - val_loss: 0.2472 - val_auc_1: 0.9728 - val_binary_accuracy: 0.9147\n",
      "Epoch 45/200\n",
      "400/400 [==============================] - 0s 746us/step - loss: 0.2413 - auc_1: 0.9737 - binary_accuracy: 0.9218 - val_loss: 0.2464 - val_auc_1: 0.9729 - val_binary_accuracy: 0.9166\n",
      "Epoch 46/200\n",
      "400/400 [==============================] - 0s 744us/step - loss: 0.2410 - auc_1: 0.9738 - binary_accuracy: 0.9209 - val_loss: 0.2462 - val_auc_1: 0.9729 - val_binary_accuracy: 0.9162\n",
      "Epoch 47/200\n",
      "400/400 [==============================] - 0s 738us/step - loss: 0.2407 - auc_1: 0.9739 - binary_accuracy: 0.9220 - val_loss: 0.2464 - val_auc_1: 0.9732 - val_binary_accuracy: 0.9156\n",
      "Epoch 48/200\n",
      "400/400 [==============================] - 0s 736us/step - loss: 0.2406 - auc_1: 0.9741 - binary_accuracy: 0.9214 - val_loss: 0.2459 - val_auc_1: 0.9734 - val_binary_accuracy: 0.9166\n",
      "Epoch 49/200\n",
      "400/400 [==============================] - 0s 815us/step - loss: 0.2405 - auc_1: 0.9741 - binary_accuracy: 0.9211 - val_loss: 0.2460 - val_auc_1: 0.9734 - val_binary_accuracy: 0.9175\n",
      "Epoch 50/200\n",
      "400/400 [==============================] - 0s 790us/step - loss: 0.2401 - auc_1: 0.9743 - binary_accuracy: 0.9225 - val_loss: 0.2458 - val_auc_1: 0.9734 - val_binary_accuracy: 0.9166\n",
      "Epoch 51/200\n",
      "400/400 [==============================] - 0s 828us/step - loss: 0.2400 - auc_1: 0.9745 - binary_accuracy: 0.9225 - val_loss: 0.2457 - val_auc_1: 0.9733 - val_binary_accuracy: 0.9194\n",
      "Epoch 52/200\n",
      "400/400 [==============================] - 0s 819us/step - loss: 0.2396 - auc_1: 0.9745 - binary_accuracy: 0.9234 - val_loss: 0.2458 - val_auc_1: 0.9740 - val_binary_accuracy: 0.9166\n",
      "Epoch 53/200\n",
      "400/400 [==============================] - 0s 919us/step - loss: 0.2396 - auc_1: 0.9746 - binary_accuracy: 0.9226 - val_loss: 0.2460 - val_auc_1: 0.9740 - val_binary_accuracy: 0.9147\n",
      "Epoch 54/200\n",
      "400/400 [==============================] - 0s 955us/step - loss: 0.2395 - auc_1: 0.9747 - binary_accuracy: 0.9235 - val_loss: 0.2448 - val_auc_1: 0.9739 - val_binary_accuracy: 0.9181\n",
      "Epoch 55/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2392 - auc_1: 0.9748 - binary_accuracy: 0.922 - 0s 1ms/step - loss: 0.2394 - auc_1: 0.9748 - binary_accuracy: 0.9232 - val_loss: 0.2442 - val_auc_1: 0.9740 - val_binary_accuracy: 0.9197\n",
      "Epoch 56/200\n",
      "400/400 [==============================] - 0s 965us/step - loss: 0.2391 - auc_1: 0.9748 - binary_accuracy: 0.9238 - val_loss: 0.2441 - val_auc_1: 0.9742 - val_binary_accuracy: 0.9187\n",
      "Epoch 57/200\n",
      "400/400 [==============================] - 0s 873us/step - loss: 0.2391 - auc_1: 0.9749 - binary_accuracy: 0.9242 - val_loss: 0.2445 - val_auc_1: 0.9744 - val_binary_accuracy: 0.9184\n",
      "Epoch 58/200\n",
      "400/400 [==============================] - 0s 962us/step - loss: 0.2388 - auc_1: 0.9751 - binary_accuracy: 0.9245 - val_loss: 0.2437 - val_auc_1: 0.9743 - val_binary_accuracy: 0.9181\n",
      "Epoch 59/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2386 - auc_1: 0.9751 - binary_accuracy: 0.9234 - val_loss: 0.2434 - val_auc_1: 0.9746 - val_binary_accuracy: 0.9197\n",
      "Epoch 60/200\n",
      "400/400 [==============================] - 0s 787us/step - loss: 0.2386 - auc_1: 0.9752 - binary_accuracy: 0.9245 - val_loss: 0.2440 - val_auc_1: 0.9745 - val_binary_accuracy: 0.9203\n",
      "Epoch 61/200\n",
      "400/400 [==============================] - 0s 794us/step - loss: 0.2386 - auc_1: 0.9752 - binary_accuracy: 0.9234 - val_loss: 0.2434 - val_auc_1: 0.9746 - val_binary_accuracy: 0.9216\n",
      "Epoch 62/200\n",
      "400/400 [==============================] - 0s 760us/step - loss: 0.2383 - auc_1: 0.9754 - binary_accuracy: 0.9249 - val_loss: 0.2442 - val_auc_1: 0.9743 - val_binary_accuracy: 0.9197\n",
      "Epoch 63/200\n",
      "400/400 [==============================] - 0s 758us/step - loss: 0.2382 - auc_1: 0.9754 - binary_accuracy: 0.9241 - val_loss: 0.2431 - val_auc_1: 0.9747 - val_binary_accuracy: 0.9197\n",
      "Epoch 64/200\n",
      "400/400 [==============================] - 0s 751us/step - loss: 0.2380 - auc_1: 0.9756 - binary_accuracy: 0.9248 - val_loss: 0.2433 - val_auc_1: 0.9747 - val_binary_accuracy: 0.9209\n",
      "Epoch 65/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2377 - auc_1: 0.9757 - binary_accuracy: 0.9247 - val_loss: 0.2428 - val_auc_1: 0.9748 - val_binary_accuracy: 0.9200\n",
      "Epoch 66/200\n",
      "400/400 [==============================] - 0s 853us/step - loss: 0.2378 - auc_1: 0.9757 - binary_accuracy: 0.9259 - val_loss: 0.2435 - val_auc_1: 0.9752 - val_binary_accuracy: 0.9206\n",
      "Epoch 67/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2377 - auc_1: 0.9759 - binary_accuracy: 0.9255 - val_loss: 0.2427 - val_auc_1: 0.9751 - val_binary_accuracy: 0.9206\n",
      "Epoch 68/200\n",
      "400/400 [==============================] - 0s 780us/step - loss: 0.2375 - auc_1: 0.9759 - binary_accuracy: 0.9256 - val_loss: 0.2420 - val_auc_1: 0.9752 - val_binary_accuracy: 0.9203\n",
      "Epoch 69/200\n",
      "400/400 [==============================] - 0s 708us/step - loss: 0.2374 - auc_1: 0.9760 - binary_accuracy: 0.9252 - val_loss: 0.2423 - val_auc_1: 0.9754 - val_binary_accuracy: 0.9222\n",
      "Epoch 70/200\n",
      "400/400 [==============================] - 0s 711us/step - loss: 0.2375 - auc_1: 0.9760 - binary_accuracy: 0.9260 - val_loss: 0.2423 - val_auc_1: 0.9753 - val_binary_accuracy: 0.9216\n",
      "Epoch 71/200\n",
      "400/400 [==============================] - 0s 813us/step - loss: 0.2372 - auc_1: 0.9761 - binary_accuracy: 0.9256 - val_loss: 0.2422 - val_auc_1: 0.9754 - val_binary_accuracy: 0.9209\n",
      "Epoch 72/200\n",
      "400/400 [==============================] - 0s 878us/step - loss: 0.2370 - auc_1: 0.9762 - binary_accuracy: 0.9252 - val_loss: 0.2426 - val_auc_1: 0.9756 - val_binary_accuracy: 0.9209\n",
      "Epoch 73/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2369 - auc_1: 0.9764 - binary_accuracy: 0.9252 - val_loss: 0.2422 - val_auc_1: 0.9753 - val_binary_accuracy: 0.9225\n",
      "Epoch 74/200\n",
      "400/400 [==============================] - 0s 962us/step - loss: 0.2369 - auc_1: 0.9762 - binary_accuracy: 0.9268 - val_loss: 0.2423 - val_auc_1: 0.9755 - val_binary_accuracy: 0.9206\n",
      "Epoch 75/200\n",
      "400/400 [==============================] - 0s 728us/step - loss: 0.2367 - auc_1: 0.9763 - binary_accuracy: 0.9259 - val_loss: 0.2425 - val_auc_1: 0.9758 - val_binary_accuracy: 0.9203\n",
      "Epoch 76/200\n",
      "400/400 [==============================] - 0s 991us/step - loss: 0.2371 - auc_1: 0.9763 - binary_accuracy: 0.9273 - val_loss: 0.2416 - val_auc_1: 0.9760 - val_binary_accuracy: 0.9216\n",
      "Epoch 77/200\n",
      "400/400 [==============================] - 0s 798us/step - loss: 0.2368 - auc_1: 0.9765 - binary_accuracy: 0.9263 - val_loss: 0.2415 - val_auc_1: 0.9758 - val_binary_accuracy: 0.9225\n",
      "Epoch 78/200\n",
      "400/400 [==============================] - 0s 913us/step - loss: 0.2367 - auc_1: 0.9764 - binary_accuracy: 0.9259 - val_loss: 0.2422 - val_auc_1: 0.9759 - val_binary_accuracy: 0.9206\n",
      "Epoch 79/200\n",
      "400/400 [==============================] - 0s 737us/step - loss: 0.2366 - auc_1: 0.9766 - binary_accuracy: 0.9251 - val_loss: 0.2413 - val_auc_1: 0.9756 - val_binary_accuracy: 0.9228\n",
      "Epoch 80/200\n",
      "400/400 [==============================] - 0s 718us/step - loss: 0.2365 - auc_1: 0.9766 - binary_accuracy: 0.9274 - val_loss: 0.2410 - val_auc_1: 0.9760 - val_binary_accuracy: 0.9216\n",
      "Epoch 81/200\n",
      "400/400 [==============================] - 0s 718us/step - loss: 0.2364 - auc_1: 0.9767 - binary_accuracy: 0.9271 - val_loss: 0.2410 - val_auc_1: 0.9759 - val_binary_accuracy: 0.9228\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 723us/step - loss: 0.2365 - auc_1: 0.9766 - binary_accuracy: 0.9270 - val_loss: 0.2411 - val_auc_1: 0.9762 - val_binary_accuracy: 0.9237\n",
      "Epoch 83/200\n",
      "400/400 [==============================] - 0s 723us/step - loss: 0.2364 - auc_1: 0.9768 - binary_accuracy: 0.9267 - val_loss: 0.2407 - val_auc_1: 0.9763 - val_binary_accuracy: 0.9216\n",
      "Epoch 84/200\n",
      "400/400 [==============================] - 0s 705us/step - loss: 0.2361 - auc_1: 0.9769 - binary_accuracy: 0.9268 - val_loss: 0.2407 - val_auc_1: 0.9762 - val_binary_accuracy: 0.9216\n",
      "Epoch 85/200\n",
      "400/400 [==============================] - 0s 723us/step - loss: 0.2359 - auc_1: 0.9769 - binary_accuracy: 0.9273 - val_loss: 0.2414 - val_auc_1: 0.9761 - val_binary_accuracy: 0.9228\n",
      "Epoch 86/200\n",
      "400/400 [==============================] - 0s 704us/step - loss: 0.2360 - auc_1: 0.9770 - binary_accuracy: 0.9283 - val_loss: 0.2409 - val_auc_1: 0.9763 - val_binary_accuracy: 0.9234\n",
      "Epoch 87/200\n",
      "400/400 [==============================] - 0s 723us/step - loss: 0.2359 - auc_1: 0.9770 - binary_accuracy: 0.9267 - val_loss: 0.2404 - val_auc_1: 0.9765 - val_binary_accuracy: 0.9231\n",
      "Epoch 88/200\n",
      "400/400 [==============================] - 0s 706us/step - loss: 0.2359 - auc_1: 0.9771 - binary_accuracy: 0.9279 - val_loss: 0.2411 - val_auc_1: 0.9765 - val_binary_accuracy: 0.9212\n",
      "Epoch 89/200\n",
      "400/400 [==============================] - 0s 713us/step - loss: 0.2358 - auc_1: 0.9772 - binary_accuracy: 0.9280 - val_loss: 0.2411 - val_auc_1: 0.9760 - val_binary_accuracy: 0.9228\n",
      "Epoch 90/200\n",
      "400/400 [==============================] - 0s 720us/step - loss: 0.2359 - auc_1: 0.9771 - binary_accuracy: 0.9274 - val_loss: 0.2403 - val_auc_1: 0.9765 - val_binary_accuracy: 0.9219\n",
      "Epoch 91/200\n",
      "400/400 [==============================] - 0s 737us/step - loss: 0.2359 - auc_1: 0.9771 - binary_accuracy: 0.9273 - val_loss: 0.2403 - val_auc_1: 0.9765 - val_binary_accuracy: 0.9231\n",
      "Epoch 92/200\n",
      "400/400 [==============================] - 0s 723us/step - loss: 0.2355 - auc_1: 0.9773 - binary_accuracy: 0.9281 - val_loss: 0.2410 - val_auc_1: 0.9763 - val_binary_accuracy: 0.9228\n",
      "Epoch 93/200\n",
      "400/400 [==============================] - 0s 713us/step - loss: 0.2354 - auc_1: 0.9773 - binary_accuracy: 0.9277 - val_loss: 0.2400 - val_auc_1: 0.9766 - val_binary_accuracy: 0.9237\n",
      "Epoch 94/200\n",
      "400/400 [==============================] - 0s 715us/step - loss: 0.2355 - auc_1: 0.9773 - binary_accuracy: 0.9277 - val_loss: 0.2408 - val_auc_1: 0.9768 - val_binary_accuracy: 0.9216\n",
      "Epoch 95/200\n",
      "400/400 [==============================] - 0s 704us/step - loss: 0.2355 - auc_1: 0.9774 - binary_accuracy: 0.9277 - val_loss: 0.2407 - val_auc_1: 0.9766 - val_binary_accuracy: 0.9237\n",
      "Epoch 96/200\n",
      "400/400 [==============================] - 0s 724us/step - loss: 0.2355 - auc_1: 0.9774 - binary_accuracy: 0.9279 - val_loss: 0.2406 - val_auc_1: 0.9769 - val_binary_accuracy: 0.9228\n",
      "Epoch 97/200\n",
      "400/400 [==============================] - 0s 736us/step - loss: 0.2353 - auc_1: 0.9775 - binary_accuracy: 0.9287 - val_loss: 0.2401 - val_auc_1: 0.9766 - val_binary_accuracy: 0.9253\n",
      "Epoch 98/200\n",
      "400/400 [==============================] - 0s 703us/step - loss: 0.2352 - auc_1: 0.9776 - binary_accuracy: 0.9286 - val_loss: 0.2406 - val_auc_1: 0.9764 - val_binary_accuracy: 0.9237\n",
      "Epoch 99/200\n",
      "400/400 [==============================] - 0s 718us/step - loss: 0.2357 - auc_1: 0.9773 - binary_accuracy: 0.9287 - val_loss: 0.2398 - val_auc_1: 0.9769 - val_binary_accuracy: 0.9247\n",
      "Epoch 100/200\n",
      "400/400 [==============================] - 0s 730us/step - loss: 0.2353 - auc_1: 0.9775 - binary_accuracy: 0.9285 - val_loss: 0.2403 - val_auc_1: 0.9769 - val_binary_accuracy: 0.9234\n",
      "Epoch 101/200\n",
      "400/400 [==============================] - 0s 714us/step - loss: 0.2352 - auc_1: 0.9776 - binary_accuracy: 0.9282 - val_loss: 0.2401 - val_auc_1: 0.9770 - val_binary_accuracy: 0.9244\n",
      "Epoch 102/200\n",
      "400/400 [==============================] - 0s 708us/step - loss: 0.2352 - auc_1: 0.9777 - binary_accuracy: 0.9293 - val_loss: 0.2402 - val_auc_1: 0.9768 - val_binary_accuracy: 0.9250\n",
      "Epoch 103/200\n",
      "400/400 [==============================] - 0s 743us/step - loss: 0.2349 - auc_1: 0.9777 - binary_accuracy: 0.9298 - val_loss: 0.2400 - val_auc_1: 0.9767 - val_binary_accuracy: 0.9269\n",
      "Epoch 104/200\n",
      "400/400 [==============================] - 0s 706us/step - loss: 0.2352 - auc_1: 0.9776 - binary_accuracy: 0.9291 - val_loss: 0.2398 - val_auc_1: 0.9773 - val_binary_accuracy: 0.9262\n",
      "Epoch 105/200\n",
      "400/400 [==============================] - 0s 717us/step - loss: 0.2348 - auc_1: 0.9778 - binary_accuracy: 0.9286 - val_loss: 0.2396 - val_auc_1: 0.9769 - val_binary_accuracy: 0.9234\n",
      "Epoch 106/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2333 - auc_1: 0.9782 - binary_accuracy: 0.928 - 0s 707us/step - loss: 0.2351 - auc_1: 0.9777 - binary_accuracy: 0.9279 - val_loss: 0.2394 - val_auc_1: 0.9769 - val_binary_accuracy: 0.9253\n",
      "Epoch 107/200\n",
      "400/400 [==============================] - 0s 708us/step - loss: 0.2347 - auc_1: 0.9777 - binary_accuracy: 0.9291 - val_loss: 0.2410 - val_auc_1: 0.9772 - val_binary_accuracy: 0.9241\n",
      "Epoch 108/200\n",
      "400/400 [==============================] - 0s 706us/step - loss: 0.2351 - auc_1: 0.9779 - binary_accuracy: 0.9299 - val_loss: 0.2393 - val_auc_1: 0.9772 - val_binary_accuracy: 0.9237\n",
      "Epoch 109/200\n",
      "400/400 [==============================] - 0s 713us/step - loss: 0.2344 - auc_1: 0.9779 - binary_accuracy: 0.9298 - val_loss: 0.2408 - val_auc_1: 0.9771 - val_binary_accuracy: 0.9212\n",
      "Epoch 110/200\n",
      "400/400 [==============================] - 0s 707us/step - loss: 0.2349 - auc_1: 0.9779 - binary_accuracy: 0.9285 - val_loss: 0.2391 - val_auc_1: 0.9772 - val_binary_accuracy: 0.9253\n",
      "Epoch 111/200\n",
      "400/400 [==============================] - 0s 730us/step - loss: 0.2351 - auc_1: 0.9778 - binary_accuracy: 0.9294 - val_loss: 0.2395 - val_auc_1: 0.9773 - val_binary_accuracy: 0.9250\n",
      "Epoch 112/200\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.2347 - auc_1: 0.9779 - binary_accuracy: 0.9294 - val_loss: 0.2395 - val_auc_1: 0.9772 - val_binary_accuracy: 0.9247s - loss: 0.2348 - auc_1: 0.9779 - binary_accuracy: 0.929\n",
      "Epoch 113/200\n",
      "400/400 [==============================] - 0s 830us/step - loss: 0.2348 - auc_1: 0.9780 - binary_accuracy: 0.9303 - val_loss: 0.2389 - val_auc_1: 0.9772 - val_binary_accuracy: 0.9278\n",
      "Epoch 114/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2348 - auc_1: 0.9779 - binary_accuracy: 0.9287 - val_loss: 0.2391 - val_auc_1: 0.9771 - val_binary_accuracy: 0.9247\n",
      "Epoch 115/200\n",
      "400/400 [==============================] - 0s 987us/step - loss: 0.2347 - auc_1: 0.9780 - binary_accuracy: 0.9298 - val_loss: 0.2390 - val_auc_1: 0.9772 - val_binary_accuracy: 0.9259\n",
      "Epoch 116/200\n",
      "400/400 [==============================] - 0s 898us/step - loss: 0.2346 - auc_1: 0.9781 - binary_accuracy: 0.9305 - val_loss: 0.2392 - val_auc_1: 0.9771 - val_binary_accuracy: 0.9247\n",
      "Epoch 117/200\n",
      "400/400 [==============================] - 0s 810us/step - loss: 0.2345 - auc_1: 0.9781 - binary_accuracy: 0.9307 - val_loss: 0.2390 - val_auc_1: 0.9773 - val_binary_accuracy: 0.9272\n",
      "Epoch 118/200\n",
      "400/400 [==============================] - 0s 913us/step - loss: 0.2345 - auc_1: 0.9781 - binary_accuracy: 0.9290 - val_loss: 0.2396 - val_auc_1: 0.9771 - val_binary_accuracy: 0.9241\n",
      "Epoch 119/200\n",
      "400/400 [==============================] - 0s 727us/step - loss: 0.2347 - auc_1: 0.9780 - binary_accuracy: 0.9298 - val_loss: 0.2391 - val_auc_1: 0.9773 - val_binary_accuracy: 0.9253\n",
      "Epoch 120/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2346 - auc_1: 0.9782 - binary_accuracy: 0.9290 - val_loss: 0.2390 - val_auc_1: 0.9774 - val_binary_accuracy: 0.9262\n",
      "Epoch 121/200\n",
      "400/400 [==============================] - 0s 890us/step - loss: 0.2346 - auc_1: 0.9781 - binary_accuracy: 0.9298 - val_loss: 0.2394 - val_auc_1: 0.9774 - val_binary_accuracy: 0.9247\n",
      "Epoch 122/200\n",
      "400/400 [==============================] - 0s 723us/step - loss: 0.2347 - auc_1: 0.9781 - binary_accuracy: 0.9308 - val_loss: 0.2391 - val_auc_1: 0.9775 - val_binary_accuracy: 0.9253\n",
      "Epoch 123/200\n",
      "400/400 [==============================] - 0s 990us/step - loss: 0.2342 - auc_1: 0.9782 - binary_accuracy: 0.9295 - val_loss: 0.2392 - val_auc_1: 0.9773 - val_binary_accuracy: 0.9272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ecfdde6580>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_dev, y_dev),\n",
    "          callbacks=[early_call])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch and Tensorboard\n",
    "Run gridsearch over hidden layer size, L2 regularization, activation, check the outputs in Tensorboard\n",
    "\n",
    "I recommend not to run Tensorboard from Jupyter notebook but from terminal directly\n",
    "\n",
    "use \"tensorboard --logdir logs\" in command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  1/200 [..............................] - ETA: 0s - loss: 1.5168 - AUC: 0.2839 - binary_accuracy: 0.4062WARNING:tensorflow:From C:\\Users\\karel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/200 [..............................] - ETA: 5s - loss: 1.6021 - AUC: 0.2904 - binary_accuracy: 0.4062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0559s). Check your callbacks.\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.1487 - AUC: 0.3033 - binary_accuracy: 0.3989 - val_loss: 0.9585 - val_AUC: 0.3134 - val_binary_accuracy: 0.3825\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8560 - AUC: 0.3694 - binary_accuracy: 0.4019 - val_loss: 0.7970 - val_AUC: 0.3838 - val_binary_accuracy: 0.4241\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 0s 823us/step - loss: 0.7555 - AUC: 0.4408 - binary_accuracy: 0.4847 - val_loss: 0.7331 - val_AUC: 0.4696 - val_binary_accuracy: 0.5181\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 0s 962us/step - loss: 0.7113 - AUC: 0.5291 - binary_accuracy: 0.5488 - val_loss: 0.6991 - val_AUC: 0.5581 - val_binary_accuracy: 0.5659\n",
      "Epoch 5/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 0.6835 - AUC: 0.6159 - binary_accuracy: 0.5955 - val_loss: 0.6733 - val_AUC: 0.6449 - val_binary_accuracy: 0.6209\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 0s 858us/step - loss: 0.6588 - AUC: 0.6902 - binary_accuracy: 0.6557 - val_loss: 0.6470 - val_AUC: 0.7125 - val_binary_accuracy: 0.6812\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.6331 - AUC: 0.7422 - binary_accuracy: 0.7038 - val_loss: 0.6195 - val_AUC: 0.7626 - val_binary_accuracy: 0.7203\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 0s 923us/step - loss: 0.6083 - AUC: 0.7806 - binary_accuracy: 0.7264 - val_loss: 0.5959 - val_AUC: 0.7954 - val_binary_accuracy: 0.7397\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 0s 930us/step - loss: 0.5884 - AUC: 0.8003 - binary_accuracy: 0.7433 - val_loss: 0.5763 - val_AUC: 0.8206 - val_binary_accuracy: 0.7569\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 0s 841us/step - loss: 0.5711 - AUC: 0.8250 - binary_accuracy: 0.7604 - val_loss: 0.5586 - val_AUC: 0.8399 - val_binary_accuracy: 0.7747\n",
      "Epoch 11/200\n",
      "200/200 [==============================] - 0s 830us/step - loss: 0.5547 - AUC: 0.8438 - binary_accuracy: 0.7748 - val_loss: 0.5427 - val_AUC: 0.8541 - val_binary_accuracy: 0.7850\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.5400 - AUC: 0.8578 - binary_accuracy: 0.7866 - val_loss: 0.5300 - val_AUC: 0.8649 - val_binary_accuracy: 0.7919\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 0s 841us/step - loss: 0.5282 - AUC: 0.8660 - binary_accuracy: 0.7959 - val_loss: 0.5199 - val_AUC: 0.8724 - val_binary_accuracy: 0.7978\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 0s 924us/step - loss: 0.5195 - AUC: 0.8702 - binary_accuracy: 0.7987 - val_loss: 0.5119 - val_AUC: 0.8775 - val_binary_accuracy: 0.7997\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 0s 876us/step - loss: 0.5130 - AUC: 0.8737 - binary_accuracy: 0.8037 - val_loss: 0.5059 - val_AUC: 0.8791 - val_binary_accuracy: 0.8047\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 0s 947us/step - loss: 0.5080 - AUC: 0.8754 - binary_accuracy: 0.8046 - val_loss: 0.5014 - val_AUC: 0.8808 - val_binary_accuracy: 0.8050\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5040 - AUC: 0.8768 - binary_accuracy: 0.8073 - val_loss: 0.4971 - val_AUC: 0.8827 - val_binary_accuracy: 0.8075\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 0s 823us/step - loss: 0.5008 - AUC: 0.8778 - binary_accuracy: 0.8087 - val_loss: 0.4942 - val_AUC: 0.8836 - val_binary_accuracy: 0.8094\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 0s 808us/step - loss: 0.4982 - AUC: 0.8791 - binary_accuracy: 0.8091 - val_loss: 0.4908 - val_AUC: 0.8849 - val_binary_accuracy: 0.8112\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.4959 - AUC: 0.8797 - binary_accuracy: 0.8121 - val_loss: 0.4886 - val_AUC: 0.8858 - val_binary_accuracy: 0.8116\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 0s 810us/step - loss: 0.4939 - AUC: 0.8800 - binary_accuracy: 0.8130 - val_loss: 0.4863 - val_AUC: 0.8866 - val_binary_accuracy: 0.8131\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 0s 823us/step - loss: 0.4922 - AUC: 0.8811 - binary_accuracy: 0.8123 - val_loss: 0.4840 - val_AUC: 0.8874 - val_binary_accuracy: 0.8141\n",
      "Epoch 23/200\n",
      "200/200 [==============================] - 0s 843us/step - loss: 0.4908 - AUC: 0.8812 - binary_accuracy: 0.8149 - val_loss: 0.4825 - val_AUC: 0.8878 - val_binary_accuracy: 0.8144\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 0s 823us/step - loss: 0.4895 - AUC: 0.8821 - binary_accuracy: 0.8145 - val_loss: 0.4807 - val_AUC: 0.8893 - val_binary_accuracy: 0.8141\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.4884 - AUC: 0.8823 - binary_accuracy: 0.8148 - val_loss: 0.4796 - val_AUC: 0.8898 - val_binary_accuracy: 0.8153\n",
      "Epoch 26/200\n",
      "200/200 [==============================] - 0s 848us/step - loss: 0.4875 - AUC: 0.8832 - binary_accuracy: 0.8150 - val_loss: 0.4780 - val_AUC: 0.8905 - val_binary_accuracy: 0.8166\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.4866 - AUC: 0.8832 - binary_accuracy: 0.8155 - val_loss: 0.4769 - val_AUC: 0.8910 - val_binary_accuracy: 0.8169\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4859 - AUC: 0.8838 - binary_accuracy: 0.8157 - val_loss: 0.4762 - val_AUC: 0.8914 - val_binary_accuracy: 0.8163\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 0s 967us/step - loss: 0.4852 - AUC: 0.8841 - binary_accuracy: 0.8136 - val_loss: 0.4753 - val_AUC: 0.8917 - val_binary_accuracy: 0.8181\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 0s 887us/step - loss: 0.4846 - AUC: 0.8847 - binary_accuracy: 0.8154 - val_loss: 0.4744 - val_AUC: 0.8918 - val_binary_accuracy: 0.8188\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 0s 862us/step - loss: 0.4841 - AUC: 0.8847 - binary_accuracy: 0.8155 - val_loss: 0.4741 - val_AUC: 0.8918 - val_binary_accuracy: 0.8194\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 0s 835us/step - loss: 0.4837 - AUC: 0.8848 - binary_accuracy: 0.8152 - val_loss: 0.4735 - val_AUC: 0.8922 - val_binary_accuracy: 0.8200\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 0s 847us/step - loss: 0.4833 - AUC: 0.8849 - binary_accuracy: 0.8158 - val_loss: 0.4729 - val_AUC: 0.8925 - val_binary_accuracy: 0.8222\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.4830 - AUC: 0.8852 - binary_accuracy: 0.8147 - val_loss: 0.4726 - val_AUC: 0.8923 - val_binary_accuracy: 0.8209\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.4826 - AUC: 0.8852 - binary_accuracy: 0.8160 - val_loss: 0.4722 - val_AUC: 0.8927 - val_binary_accuracy: 0.8216\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 0s 838us/step - loss: 0.4823 - AUC: 0.8855 - binary_accuracy: 0.8160 - val_loss: 0.4718 - val_AUC: 0.8926 - val_binary_accuracy: 0.8222\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 0s 849us/step - loss: 0.4821 - AUC: 0.8855 - binary_accuracy: 0.8162 - val_loss: 0.4715 - val_AUC: 0.8929 - val_binary_accuracy: 0.8238\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 0s 841us/step - loss: 0.4817 - AUC: 0.8857 - binary_accuracy: 0.8176 - val_loss: 0.4714 - val_AUC: 0.8931 - val_binary_accuracy: 0.8244\n",
      "Epoch 39/200\n",
      "200/200 [==============================] - 0s 883us/step - loss: 0.4814 - AUC: 0.8862 - binary_accuracy: 0.8168 - val_loss: 0.4710 - val_AUC: 0.8929 - val_binary_accuracy: 0.8222\n",
      "Epoch 40/200\n",
      "200/200 [==============================] - 0s 878us/step - loss: 0.4812 - AUC: 0.8860 - binary_accuracy: 0.8176 - val_loss: 0.4712 - val_AUC: 0.8929 - val_binary_accuracy: 0.8219\n",
      "Epoch 41/200\n",
      "200/200 [==============================] - 0s 853us/step - loss: 0.4810 - AUC: 0.8863 - binary_accuracy: 0.8161 - val_loss: 0.4709 - val_AUC: 0.8930 - val_binary_accuracy: 0.8225\n",
      "Epoch 42/200\n",
      "200/200 [==============================] - 0s 834us/step - loss: 0.4807 - AUC: 0.8863 - binary_accuracy: 0.8164 - val_loss: 0.4704 - val_AUC: 0.8932 - val_binary_accuracy: 0.8228\n",
      "Epoch 43/200\n",
      "200/200 [==============================] - 0s 848us/step - loss: 0.4806 - AUC: 0.8865 - binary_accuracy: 0.8162 - val_loss: 0.4703 - val_AUC: 0.8933 - val_binary_accuracy: 0.8231\n",
      "Epoch 44/200\n",
      "200/200 [==============================] - 0s 856us/step - loss: 0.4804 - AUC: 0.8866 - binary_accuracy: 0.8166 - val_loss: 0.4700 - val_AUC: 0.8934 - val_binary_accuracy: 0.8234\n",
      "Epoch 45/200\n",
      "200/200 [==============================] - 0s 863us/step - loss: 0.4802 - AUC: 0.8867 - binary_accuracy: 0.8174 - val_loss: 0.4702 - val_AUC: 0.8934 - val_binary_accuracy: 0.8238\n",
      "Epoch 46/200\n",
      "200/200 [==============================] - 0s 873us/step - loss: 0.4801 - AUC: 0.8868 - binary_accuracy: 0.8161 - val_loss: 0.4701 - val_AUC: 0.8934 - val_binary_accuracy: 0.8247\n",
      "Epoch 47/200\n",
      "200/200 [==============================] - 0s 857us/step - loss: 0.4799 - AUC: 0.8871 - binary_accuracy: 0.8155 - val_loss: 0.4699 - val_AUC: 0.8934 - val_binary_accuracy: 0.8278\n",
      "Epoch 48/200\n",
      "200/200 [==============================] - 0s 863us/step - loss: 0.4799 - AUC: 0.8870 - binary_accuracy: 0.8166 - val_loss: 0.4694 - val_AUC: 0.8936 - val_binary_accuracy: 0.8259\n",
      "Epoch 49/200\n",
      "200/200 [==============================] - 0s 824us/step - loss: 0.4797 - AUC: 0.8871 - binary_accuracy: 0.8170 - val_loss: 0.4693 - val_AUC: 0.8937 - val_binary_accuracy: 0.8247\n",
      "Epoch 50/200\n",
      "200/200 [==============================] - 0s 853us/step - loss: 0.4795 - AUC: 0.8873 - binary_accuracy: 0.8172 - val_loss: 0.4694 - val_AUC: 0.8935 - val_binary_accuracy: 0.8253\n",
      "Epoch 51/200\n",
      "200/200 [==============================] - 0s 854us/step - loss: 0.4792 - AUC: 0.8874 - binary_accuracy: 0.8173 - val_loss: 0.4693 - val_AUC: 0.8937 - val_binary_accuracy: 0.8266\n",
      "Epoch 52/200\n",
      "200/200 [==============================] - 0s 888us/step - loss: 0.4793 - AUC: 0.8875 - binary_accuracy: 0.8179 - val_loss: 0.4695 - val_AUC: 0.8939 - val_binary_accuracy: 0.8281\n",
      "Epoch 53/200\n",
      "200/200 [==============================] - 0s 868us/step - loss: 0.4791 - AUC: 0.8878 - binary_accuracy: 0.8188 - val_loss: 0.4688 - val_AUC: 0.8943 - val_binary_accuracy: 0.8281\n",
      "Epoch 54/200\n",
      "200/200 [==============================] - 0s 838us/step - loss: 0.4790 - AUC: 0.8875 - binary_accuracy: 0.8180 - val_loss: 0.4688 - val_AUC: 0.8942 - val_binary_accuracy: 0.8263\n",
      "Epoch 55/200\n",
      "200/200 [==============================] - 0s 893us/step - loss: 0.4789 - AUC: 0.8879 - binary_accuracy: 0.8180 - val_loss: 0.4691 - val_AUC: 0.8941 - val_binary_accuracy: 0.8269\n",
      "Epoch 56/200\n",
      "200/200 [==============================] - 0s 878us/step - loss: 0.4787 - AUC: 0.8881 - binary_accuracy: 0.8177 - val_loss: 0.4687 - val_AUC: 0.8942 - val_binary_accuracy: 0.8234\n",
      "Epoch 57/200\n",
      "200/200 [==============================] - 0s 914us/step - loss: 0.4786 - AUC: 0.8881 - binary_accuracy: 0.8184 - val_loss: 0.4686 - val_AUC: 0.8941 - val_binary_accuracy: 0.8250\n",
      "Epoch 58/200\n",
      "200/200 [==============================] - 0s 984us/step - loss: 0.4785 - AUC: 0.8878 - binary_accuracy: 0.8183 - val_loss: 0.4686 - val_AUC: 0.8943 - val_binary_accuracy: 0.8275\n",
      "Epoch 59/200\n",
      "200/200 [==============================] - 0s 902us/step - loss: 0.4784 - AUC: 0.8883 - binary_accuracy: 0.8182 - val_loss: 0.4687 - val_AUC: 0.8943 - val_binary_accuracy: 0.8241\n",
      "Epoch 60/200\n",
      "200/200 [==============================] - 0s 897us/step - loss: 0.4783 - AUC: 0.8882 - binary_accuracy: 0.8179 - val_loss: 0.4686 - val_AUC: 0.8945 - val_binary_accuracy: 0.8241\n",
      "Epoch 61/200\n",
      "200/200 [==============================] - 0s 925us/step - loss: 0.4784 - AUC: 0.8882 - binary_accuracy: 0.8176 - val_loss: 0.4685 - val_AUC: 0.8942 - val_binary_accuracy: 0.8259\n",
      "Epoch 62/200\n",
      "200/200 [==============================] - 0s 894us/step - loss: 0.4783 - AUC: 0.8883 - binary_accuracy: 0.8188 - val_loss: 0.4684 - val_AUC: 0.8945 - val_binary_accuracy: 0.8269\n",
      "Epoch 63/200\n",
      "200/200 [==============================] - 0s 898us/step - loss: 0.4781 - AUC: 0.8884 - binary_accuracy: 0.8181 - val_loss: 0.4687 - val_AUC: 0.8946 - val_binary_accuracy: 0.8259\n",
      "Epoch 64/200\n",
      "200/200 [==============================] - 0s 908us/step - loss: 0.4781 - AUC: 0.8884 - binary_accuracy: 0.8180 - val_loss: 0.4687 - val_AUC: 0.8947 - val_binary_accuracy: 0.8259\n",
      "Epoch 65/200\n",
      "200/200 [==============================] - 0s 915us/step - loss: 0.4780 - AUC: 0.8886 - binary_accuracy: 0.8182 - val_loss: 0.4684 - val_AUC: 0.8946 - val_binary_accuracy: 0.8269\n",
      "Epoch 66/200\n",
      "200/200 [==============================] - 0s 896us/step - loss: 0.4781 - AUC: 0.8884 - binary_accuracy: 0.8178 - val_loss: 0.4684 - val_AUC: 0.8946 - val_binary_accuracy: 0.8269\n",
      "Epoch 67/200\n",
      "200/200 [==============================] - 0s 942us/step - loss: 0.4779 - AUC: 0.8888 - binary_accuracy: 0.8183 - val_loss: 0.4684 - val_AUC: 0.8948 - val_binary_accuracy: 0.8250\n",
      "Epoch 68/200\n",
      "200/200 [==============================] - 0s 917us/step - loss: 0.4778 - AUC: 0.8887 - binary_accuracy: 0.8174 - val_loss: 0.4683 - val_AUC: 0.8949 - val_binary_accuracy: 0.8278\n",
      "Epoch 69/200\n",
      "200/200 [==============================] - 0s 916us/step - loss: 0.4778 - AUC: 0.8889 - binary_accuracy: 0.8184 - val_loss: 0.4682 - val_AUC: 0.8949 - val_binary_accuracy: 0.8275\n",
      "Epoch 70/200\n",
      "200/200 [==============================] - 0s 885us/step - loss: 0.4777 - AUC: 0.8889 - binary_accuracy: 0.8184 - val_loss: 0.4679 - val_AUC: 0.8952 - val_binary_accuracy: 0.8272\n",
      "Epoch 71/200\n",
      "200/200 [==============================] - 0s 891us/step - loss: 0.4777 - AUC: 0.8890 - binary_accuracy: 0.8195 - val_loss: 0.4680 - val_AUC: 0.8949 - val_binary_accuracy: 0.8256\n",
      "Epoch 72/200\n",
      "200/200 [==============================] - 0s 888us/step - loss: 0.4776 - AUC: 0.8891 - binary_accuracy: 0.8187 - val_loss: 0.4679 - val_AUC: 0.8948 - val_binary_accuracy: 0.8272\n",
      "Epoch 73/200\n",
      "200/200 [==============================] - 0s 898us/step - loss: 0.4775 - AUC: 0.8890 - binary_accuracy: 0.8184 - val_loss: 0.4680 - val_AUC: 0.8950 - val_binary_accuracy: 0.8284\n",
      "Epoch 74/200\n",
      "200/200 [==============================] - 0s 888us/step - loss: 0.4775 - AUC: 0.8889 - binary_accuracy: 0.8184 - val_loss: 0.4679 - val_AUC: 0.8951 - val_binary_accuracy: 0.8284\n",
      "Epoch 75/200\n",
      "200/200 [==============================] - 0s 878us/step - loss: 0.4774 - AUC: 0.8893 - binary_accuracy: 0.8198 - val_loss: 0.4681 - val_AUC: 0.8949 - val_binary_accuracy: 0.8263\n",
      "Epoch 76/200\n",
      "200/200 [==============================] - 0s 888us/step - loss: 0.4774 - AUC: 0.8889 - binary_accuracy: 0.8176 - val_loss: 0.4679 - val_AUC: 0.8953 - val_binary_accuracy: 0.8284\n",
      "Epoch 77/200\n",
      "200/200 [==============================] - 0s 883us/step - loss: 0.4774 - AUC: 0.8892 - binary_accuracy: 0.8195 - val_loss: 0.4678 - val_AUC: 0.8951 - val_binary_accuracy: 0.8256\n",
      "Epoch 78/200\n",
      "200/200 [==============================] - 0s 900us/step - loss: 0.4773 - AUC: 0.8893 - binary_accuracy: 0.8182 - val_loss: 0.4678 - val_AUC: 0.8952 - val_binary_accuracy: 0.8269\n",
      "Epoch 79/200\n",
      "200/200 [==============================] - 0s 894us/step - loss: 0.4771 - AUC: 0.8893 - binary_accuracy: 0.8183 - val_loss: 0.4680 - val_AUC: 0.8952 - val_binary_accuracy: 0.8263\n",
      "Epoch 80/200\n",
      "200/200 [==============================] - 0s 870us/step - loss: 0.4773 - AUC: 0.8892 - binary_accuracy: 0.8178 - val_loss: 0.4677 - val_AUC: 0.8954 - val_binary_accuracy: 0.8281\n",
      "Epoch 81/200\n",
      "200/200 [==============================] - 0s 898us/step - loss: 0.4772 - AUC: 0.8892 - binary_accuracy: 0.8181 - val_loss: 0.4677 - val_AUC: 0.8954 - val_binary_accuracy: 0.8291\n",
      "Epoch 82/200\n",
      "200/200 [==============================] - 0s 827us/step - loss: 0.4771 - AUC: 0.8894 - binary_accuracy: 0.8188 - val_loss: 0.4679 - val_AUC: 0.8953 - val_binary_accuracy: 0.8269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "200/200 [==============================] - 0s 878us/step - loss: 0.4771 - AUC: 0.8896 - binary_accuracy: 0.8181 - val_loss: 0.4676 - val_AUC: 0.8952 - val_binary_accuracy: 0.8272\n",
      "Epoch 84/200\n",
      "200/200 [==============================] - 0s 873us/step - loss: 0.4770 - AUC: 0.8895 - binary_accuracy: 0.8187 - val_loss: 0.4676 - val_AUC: 0.8956 - val_binary_accuracy: 0.8256\n",
      "Epoch 85/200\n",
      "200/200 [==============================] - 0s 838us/step - loss: 0.4770 - AUC: 0.8895 - binary_accuracy: 0.8182 - val_loss: 0.4679 - val_AUC: 0.8953 - val_binary_accuracy: 0.8266\n",
      "Epoch 86/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4769 - AUC: 0.8896 - binary_accuracy: 0.8179 - val_loss: 0.4676 - val_AUC: 0.8956 - val_binary_accuracy: 0.8272\n",
      "Epoch 87/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4769 - AUC: 0.8896 - binary_accuracy: 0.8194 - val_loss: 0.4675 - val_AUC: 0.8955 - val_binary_accuracy: 0.8281\n",
      "Epoch 88/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4769 - AUC: 0.8895 - binary_accuracy: 0.8182 - val_loss: 0.4675 - val_AUC: 0.8957 - val_binary_accuracy: 0.8281\n",
      "Epoch 89/200\n",
      "200/200 [==============================] - 0s 996us/step - loss: 0.4768 - AUC: 0.8897 - binary_accuracy: 0.8184 - val_loss: 0.4676 - val_AUC: 0.8955 - val_binary_accuracy: 0.8281\n",
      "Epoch 90/200\n",
      "200/200 [==============================] - 0s 991us/step - loss: 0.4768 - AUC: 0.8898 - binary_accuracy: 0.8181 - val_loss: 0.4678 - val_AUC: 0.8955 - val_binary_accuracy: 0.8278\n",
      "Epoch 91/200\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.4767 - AUC: 0.8898 - binary_accuracy: 0.8191 - val_loss: 0.4675 - val_AUC: 0.8956 - val_binary_accuracy: 0.8256\n",
      "Epoch 92/200\n",
      "200/200 [==============================] - 0s 917us/step - loss: 0.4767 - AUC: 0.8899 - binary_accuracy: 0.8191 - val_loss: 0.4676 - val_AUC: 0.8957 - val_binary_accuracy: 0.8238\n",
      "Epoch 93/200\n",
      "200/200 [==============================] - 0s 923us/step - loss: 0.4766 - AUC: 0.8899 - binary_accuracy: 0.8192 - val_loss: 0.4674 - val_AUC: 0.8958 - val_binary_accuracy: 0.8234\n",
      "Epoch 94/200\n",
      "200/200 [==============================] - 0s 885us/step - loss: 0.4767 - AUC: 0.8900 - binary_accuracy: 0.8184 - val_loss: 0.4674 - val_AUC: 0.8955 - val_binary_accuracy: 0.8272\n",
      "Epoch 95/200\n",
      "200/200 [==============================] - 0s 903us/step - loss: 0.4765 - AUC: 0.8900 - binary_accuracy: 0.8196 - val_loss: 0.4674 - val_AUC: 0.8958 - val_binary_accuracy: 0.8272\n",
      "Epoch 96/200\n",
      "200/200 [==============================] - 0s 929us/step - loss: 0.4767 - AUC: 0.8899 - binary_accuracy: 0.8184 - val_loss: 0.4674 - val_AUC: 0.8959 - val_binary_accuracy: 0.8238\n",
      "Epoch 97/200\n",
      "200/200 [==============================] - 0s 895us/step - loss: 0.4766 - AUC: 0.8900 - binary_accuracy: 0.8186 - val_loss: 0.4676 - val_AUC: 0.8960 - val_binary_accuracy: 0.8259\n",
      "Epoch 98/200\n",
      "200/200 [==============================] - 0s 910us/step - loss: 0.4766 - AUC: 0.8900 - binary_accuracy: 0.8179 - val_loss: 0.4674 - val_AUC: 0.8961 - val_binary_accuracy: 0.8269\n",
      "Epoch 99/200\n",
      "200/200 [==============================] - 0s 918us/step - loss: 0.4764 - AUC: 0.8901 - binary_accuracy: 0.8193 - val_loss: 0.4673 - val_AUC: 0.8960 - val_binary_accuracy: 0.8253\n",
      "Epoch 100/200\n",
      "200/200 [==============================] - 0s 914us/step - loss: 0.4765 - AUC: 0.8901 - binary_accuracy: 0.8199 - val_loss: 0.4672 - val_AUC: 0.8962 - val_binary_accuracy: 0.8278\n",
      "Epoch 101/200\n",
      "200/200 [==============================] - 0s 978us/step - loss: 0.4764 - AUC: 0.8901 - binary_accuracy: 0.8197 - val_loss: 0.4675 - val_AUC: 0.8959 - val_binary_accuracy: 0.8253\n",
      "Epoch 102/200\n",
      "200/200 [==============================] - 0s 908us/step - loss: 0.4765 - AUC: 0.8901 - binary_accuracy: 0.8195 - val_loss: 0.4675 - val_AUC: 0.8961 - val_binary_accuracy: 0.8241\n",
      "Epoch 103/200\n",
      "200/200 [==============================] - 0s 878us/step - loss: 0.4764 - AUC: 0.8901 - binary_accuracy: 0.8186 - val_loss: 0.4673 - val_AUC: 0.8962 - val_binary_accuracy: 0.8250\n",
      "Epoch 104/200\n",
      "200/200 [==============================] - 0s 883us/step - loss: 0.4764 - AUC: 0.8901 - binary_accuracy: 0.8193 - val_loss: 0.4673 - val_AUC: 0.8962 - val_binary_accuracy: 0.8253\n",
      "Epoch 105/200\n",
      "200/200 [==============================] - 0s 888us/step - loss: 0.4763 - AUC: 0.8902 - binary_accuracy: 0.8190 - val_loss: 0.4673 - val_AUC: 0.8961 - val_binary_accuracy: 0.8278\n",
      "Epoch 106/200\n",
      "200/200 [==============================] - 0s 875us/step - loss: 0.4763 - AUC: 0.8903 - binary_accuracy: 0.8199 - val_loss: 0.4673 - val_AUC: 0.8960 - val_binary_accuracy: 0.8238\n",
      "Epoch 107/200\n",
      "200/200 [==============================] - 0s 894us/step - loss: 0.4762 - AUC: 0.8902 - binary_accuracy: 0.8195 - val_loss: 0.4672 - val_AUC: 0.8961 - val_binary_accuracy: 0.8259\n",
      "Epoch 108/200\n",
      "200/200 [==============================] - 0s 842us/step - loss: 0.4762 - AUC: 0.8903 - binary_accuracy: 0.8194 - val_loss: 0.4671 - val_AUC: 0.8962 - val_binary_accuracy: 0.8284\n",
      "Epoch 109/200\n",
      "200/200 [==============================] - 0s 814us/step - loss: 0.4762 - AUC: 0.8902 - binary_accuracy: 0.8200 - val_loss: 0.4673 - val_AUC: 0.8964 - val_binary_accuracy: 0.8253\n",
      "Epoch 110/200\n",
      "200/200 [==============================] - 0s 823us/step - loss: 0.4760 - AUC: 0.8906 - binary_accuracy: 0.8191 - val_loss: 0.4671 - val_AUC: 0.8962 - val_binary_accuracy: 0.8275\n",
      "Epoch 111/200\n",
      "200/200 [==============================] - 0s 834us/step - loss: 0.4763 - AUC: 0.8902 - binary_accuracy: 0.8204 - val_loss: 0.4671 - val_AUC: 0.8961 - val_binary_accuracy: 0.8284\n",
      "Epoch 112/200\n",
      "200/200 [==============================] - 0s 813us/step - loss: 0.4762 - AUC: 0.8904 - binary_accuracy: 0.8200 - val_loss: 0.4672 - val_AUC: 0.8960 - val_binary_accuracy: 0.8238\n",
      "Epoch 113/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 0.4761 - AUC: 0.8903 - binary_accuracy: 0.8206 - val_loss: 0.4667 - val_AUC: 0.8962 - val_binary_accuracy: 0.8275\n",
      "Epoch 114/200\n",
      "200/200 [==============================] - 0s 803us/step - loss: 0.4761 - AUC: 0.8903 - binary_accuracy: 0.8190 - val_loss: 0.4670 - val_AUC: 0.8964 - val_binary_accuracy: 0.8275\n",
      "Epoch 115/200\n",
      "200/200 [==============================] - 0s 813us/step - loss: 0.4761 - AUC: 0.8904 - binary_accuracy: 0.8194 - val_loss: 0.4668 - val_AUC: 0.8965 - val_binary_accuracy: 0.8259\n",
      "Epoch 116/200\n",
      "200/200 [==============================] - 0s 823us/step - loss: 0.4761 - AUC: 0.8905 - binary_accuracy: 0.8205 - val_loss: 0.4666 - val_AUC: 0.8964 - val_binary_accuracy: 0.8244\n",
      "Epoch 117/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 0.4760 - AUC: 0.8903 - binary_accuracy: 0.8195 - val_loss: 0.4668 - val_AUC: 0.8963 - val_binary_accuracy: 0.8272\n",
      "Epoch 118/200\n",
      "200/200 [==============================] - 0s 826us/step - loss: 0.4760 - AUC: 0.8903 - binary_accuracy: 0.8198 - val_loss: 0.4669 - val_AUC: 0.8966 - val_binary_accuracy: 0.8269\n",
      "Epoch 119/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.4761 - AUC: 0.8905 - binary_accuracy: 0.8205 - val_loss: 0.4667 - val_AUC: 0.8962 - val_binary_accuracy: 0.8259\n",
      "Epoch 120/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.4760 - AUC: 0.8903 - binary_accuracy: 0.8200 - val_loss: 0.4668 - val_AUC: 0.8964 - val_binary_accuracy: 0.8244\n",
      "Epoch 121/200\n",
      "200/200 [==============================] - 0s 859us/step - loss: 0.4760 - AUC: 0.8906 - binary_accuracy: 0.8186 - val_loss: 0.4666 - val_AUC: 0.8963 - val_binary_accuracy: 0.8269\n",
      "Epoch 122/200\n",
      "200/200 [==============================] - 0s 848us/step - loss: 0.4759 - AUC: 0.8905 - binary_accuracy: 0.8198 - val_loss: 0.4668 - val_AUC: 0.8965 - val_binary_accuracy: 0.8253\n",
      "Epoch 123/200\n",
      "200/200 [==============================] - 0s 842us/step - loss: 0.4758 - AUC: 0.8906 - binary_accuracy: 0.8203 - val_loss: 0.4667 - val_AUC: 0.8962 - val_binary_accuracy: 0.8269\n",
      "Epoch 124/200\n",
      "200/200 [==============================] - 0s 836us/step - loss: 0.4758 - AUC: 0.8906 - binary_accuracy: 0.8202 - val_loss: 0.4665 - val_AUC: 0.8966 - val_binary_accuracy: 0.8238\n",
      "Epoch 125/200\n",
      "200/200 [==============================] - 0s 834us/step - loss: 0.4759 - AUC: 0.8905 - binary_accuracy: 0.8188 - val_loss: 0.4666 - val_AUC: 0.8966 - val_binary_accuracy: 0.8247\n",
      "Epoch 126/200\n",
      "200/200 [==============================] - 0s 912us/step - loss: 0.4759 - AUC: 0.8905 - binary_accuracy: 0.8199 - val_loss: 0.4665 - val_AUC: 0.8966 - val_binary_accuracy: 0.8263\n",
      "Epoch 127/200\n",
      "200/200 [==============================] - 0s 898us/step - loss: 0.4758 - AUC: 0.8907 - binary_accuracy: 0.8198 - val_loss: 0.4665 - val_AUC: 0.8965 - val_binary_accuracy: 0.8281\n",
      "Epoch 128/200\n",
      "200/200 [==============================] - 0s 941us/step - loss: 0.4760 - AUC: 0.8904 - binary_accuracy: 0.8193 - val_loss: 0.4666 - val_AUC: 0.8967 - val_binary_accuracy: 0.8259\n",
      "Epoch 129/200\n",
      "200/200 [==============================] - 0s 908us/step - loss: 0.4759 - AUC: 0.8905 - binary_accuracy: 0.8206 - val_loss: 0.4666 - val_AUC: 0.8967 - val_binary_accuracy: 0.8259\n",
      "Epoch 130/200\n",
      "200/200 [==============================] - 0s 857us/step - loss: 0.4758 - AUC: 0.8908 - binary_accuracy: 0.8193 - val_loss: 0.4669 - val_AUC: 0.8961 - val_binary_accuracy: 0.8241\n",
      "Epoch 131/200\n",
      "200/200 [==============================] - 0s 838us/step - loss: 0.4758 - AUC: 0.8904 - binary_accuracy: 0.8198 - val_loss: 0.4666 - val_AUC: 0.8966 - val_binary_accuracy: 0.8219\n",
      "Epoch 132/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.4758 - AUC: 0.8906 - binary_accuracy: 0.8179 - val_loss: 0.4666 - val_AUC: 0.8965 - val_binary_accuracy: 0.8256\n",
      "Epoch 133/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4758 - AUC: 0.8907 - binary_accuracy: 0.8205 - val_loss: 0.4664 - val_AUC: 0.8965 - val_binary_accuracy: 0.8272\n",
      "Epoch 134/200\n",
      "200/200 [==============================] - 0s 813us/step - loss: 0.4757 - AUC: 0.8905 - binary_accuracy: 0.8199 - val_loss: 0.4668 - val_AUC: 0.8965 - val_binary_accuracy: 0.8247\n",
      "Epoch 135/200\n",
      "200/200 [==============================] - 0s 813us/step - loss: 0.4757 - AUC: 0.8908 - binary_accuracy: 0.8198 - val_loss: 0.4665 - val_AUC: 0.8967 - val_binary_accuracy: 0.8244\n",
      "Epoch 136/200\n",
      "200/200 [==============================] - 0s 942us/step - loss: 0.4757 - AUC: 0.8907 - binary_accuracy: 0.8195 - val_loss: 0.4667 - val_AUC: 0.8966 - val_binary_accuracy: 0.8247\n",
      "Epoch 137/200\n",
      "200/200 [==============================] - 0s 852us/step - loss: 0.4756 - AUC: 0.8909 - binary_accuracy: 0.8197 - val_loss: 0.4664 - val_AUC: 0.8967 - val_binary_accuracy: 0.8263\n",
      "Epoch 138/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.4757 - AUC: 0.8907 - binary_accuracy: 0.8205 - val_loss: 0.4668 - val_AUC: 0.8968 - val_binary_accuracy: 0.8231\n",
      "Epoch 139/200\n",
      "200/200 [==============================] - 0s 839us/step - loss: 0.4757 - AUC: 0.8908 - binary_accuracy: 0.8202 - val_loss: 0.4665 - val_AUC: 0.8963 - val_binary_accuracy: 0.8231\n",
      "Epoch 140/200\n",
      "200/200 [==============================] - 0s 843us/step - loss: 0.4757 - AUC: 0.8908 - binary_accuracy: 0.8188 - val_loss: 0.4663 - val_AUC: 0.8964 - val_binary_accuracy: 0.8263\n",
      "Epoch 141/200\n",
      "200/200 [==============================] - 0s 840us/step - loss: 0.4757 - AUC: 0.8907 - binary_accuracy: 0.8193 - val_loss: 0.4664 - val_AUC: 0.8966 - val_binary_accuracy: 0.8238\n",
      "Epoch 142/200\n",
      "200/200 [==============================] - 0s 860us/step - loss: 0.4757 - AUC: 0.8908 - binary_accuracy: 0.8187 - val_loss: 0.4664 - val_AUC: 0.8966 - val_binary_accuracy: 0.8266\n",
      "Epoch 143/200\n",
      "200/200 [==============================] - 0s 837us/step - loss: 0.4756 - AUC: 0.8908 - binary_accuracy: 0.8200 - val_loss: 0.4663 - val_AUC: 0.8967 - val_binary_accuracy: 0.8259\n",
      "Epoch 144/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.4757 - AUC: 0.8908 - binary_accuracy: 0.8196 - val_loss: 0.4662 - val_AUC: 0.8966 - val_binary_accuracy: 0.8241\n",
      "Epoch 145/200\n",
      "200/200 [==============================] - 0s 834us/step - loss: 0.4756 - AUC: 0.8907 - binary_accuracy: 0.8193 - val_loss: 0.4661 - val_AUC: 0.8968 - val_binary_accuracy: 0.8263\n",
      "Epoch 146/200\n",
      "200/200 [==============================] - 0s 846us/step - loss: 0.4755 - AUC: 0.8909 - binary_accuracy: 0.8208 - val_loss: 0.4660 - val_AUC: 0.8968 - val_binary_accuracy: 0.8247\n",
      "Epoch 147/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.4755 - AUC: 0.8911 - binary_accuracy: 0.8194 - val_loss: 0.4660 - val_AUC: 0.8966 - val_binary_accuracy: 0.8259\n",
      "Epoch 148/200\n",
      "200/200 [==============================] - 0s 880us/step - loss: 0.4755 - AUC: 0.8907 - binary_accuracy: 0.8203 - val_loss: 0.4663 - val_AUC: 0.8969 - val_binary_accuracy: 0.8266\n",
      "Epoch 149/200\n",
      "200/200 [==============================] - 0s 866us/step - loss: 0.4755 - AUC: 0.8909 - binary_accuracy: 0.8190 - val_loss: 0.4662 - val_AUC: 0.8965 - val_binary_accuracy: 0.8253\n",
      "Epoch 150/200\n",
      "200/200 [==============================] - 0s 848us/step - loss: 0.4755 - AUC: 0.8909 - binary_accuracy: 0.8188 - val_loss: 0.4664 - val_AUC: 0.8967 - val_binary_accuracy: 0.8253\n",
      "Epoch 151/200\n",
      "200/200 [==============================] - 0s 872us/step - loss: 0.4754 - AUC: 0.8909 - binary_accuracy: 0.8198 - val_loss: 0.4664 - val_AUC: 0.8968 - val_binary_accuracy: 0.8247\n",
      "Epoch 152/200\n",
      "200/200 [==============================] - 0s 921us/step - loss: 0.4755 - AUC: 0.8908 - binary_accuracy: 0.8191 - val_loss: 0.4664 - val_AUC: 0.8967 - val_binary_accuracy: 0.8231\n",
      "Epoch 153/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4754 - AUC: 0.8910 - binary_accuracy: 0.8180 - val_loss: 0.4661 - val_AUC: 0.8968 - val_binary_accuracy: 0.8269\n",
      "Epoch 154/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4754 - AUC: 0.8910 - binary_accuracy: 0.8205 - val_loss: 0.4664 - val_AUC: 0.8967 - val_binary_accuracy: 0.8231\n",
      "Epoch 155/200\n",
      "200/200 [==============================] - 0s 888us/step - loss: 0.4756 - AUC: 0.8908 - binary_accuracy: 0.8194 - val_loss: 0.4660 - val_AUC: 0.8969 - val_binary_accuracy: 0.8241\n",
      "Epoch 156/200\n",
      "200/200 [==============================] - 0s 846us/step - loss: 0.4754 - AUC: 0.8909 - binary_accuracy: 0.8202 - val_loss: 0.4662 - val_AUC: 0.8970 - val_binary_accuracy: 0.8250\n",
      "Epoch 157/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4755 - AUC: 0.8910 - binary_accuracy: 0.8187 - val_loss: 0.4664 - val_AUC: 0.8967 - val_binary_accuracy: 0.8244\n",
      "Epoch 158/200\n",
      "200/200 [==============================] - 0s 843us/step - loss: 0.4755 - AUC: 0.8909 - binary_accuracy: 0.8204 - val_loss: 0.4662 - val_AUC: 0.8970 - val_binary_accuracy: 0.8259\n",
      "Epoch 159/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4754 - AUC: 0.8909 - binary_accuracy: 0.8191 - val_loss: 0.4661 - val_AUC: 0.8969 - val_binary_accuracy: 0.8247\n",
      "Epoch 160/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.4754 - AUC: 0.8911 - binary_accuracy: 0.8198 - val_loss: 0.4664 - val_AUC: 0.8968 - val_binary_accuracy: 0.8228\n",
      "Epoch 161/200\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.4754 - AUC: 0.8910 - binary_accuracy: 0.8192 - val_loss: 0.4660 - val_AUC: 0.8970 - val_binary_accuracy: 0.8259\n",
      "Epoch 162/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4754 - AUC: 0.8910 - binary_accuracy: 0.8195 - val_loss: 0.4661 - val_AUC: 0.8969 - val_binary_accuracy: 0.8247\n",
      "Epoch 163/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4754 - AUC: 0.8909 - binary_accuracy: 0.8195 - val_loss: 0.4661 - val_AUC: 0.8970 - val_binary_accuracy: 0.8253\n",
      "Epoch 164/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4754 - AUC: 0.8911 - binary_accuracy: 0.8195 - val_loss: 0.4658 - val_AUC: 0.8970 - val_binary_accuracy: 0.8269\n",
      "Epoch 165/200\n",
      "200/200 [==============================] - 0s 866us/step - loss: 0.4752 - AUC: 0.8911 - binary_accuracy: 0.8204 - val_loss: 0.4659 - val_AUC: 0.8970 - val_binary_accuracy: 0.8253\n",
      "Epoch 166/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4754 - AUC: 0.8911 - binary_accuracy: 0.8185 - val_loss: 0.4659 - val_AUC: 0.8970 - val_binary_accuracy: 0.8250\n",
      "Epoch 167/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4752 - AUC: 0.8912 - binary_accuracy: 0.8188 - val_loss: 0.4660 - val_AUC: 0.8970 - val_binary_accuracy: 0.8253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200\n",
      "200/200 [==============================] - 0s 878us/step - loss: 0.4754 - AUC: 0.8910 - binary_accuracy: 0.8195 - val_loss: 0.4660 - val_AUC: 0.8973 - val_binary_accuracy: 0.8278\n",
      "Epoch 169/200\n",
      "200/200 [==============================] - 0s 871us/step - loss: 0.4754 - AUC: 0.8910 - binary_accuracy: 0.8191 - val_loss: 0.4659 - val_AUC: 0.8971 - val_binary_accuracy: 0.8272\n",
      "Epoch 170/200\n",
      "200/200 [==============================] - 0s 871us/step - loss: 0.4753 - AUC: 0.8911 - binary_accuracy: 0.8187 - val_loss: 0.4660 - val_AUC: 0.8970 - val_binary_accuracy: 0.8256\n",
      "Epoch 171/200\n",
      "200/200 [==============================] - 0s 887us/step - loss: 0.4753 - AUC: 0.8911 - binary_accuracy: 0.8202 - val_loss: 0.4660 - val_AUC: 0.8971 - val_binary_accuracy: 0.8225\n",
      "Epoch 172/200\n",
      "200/200 [==============================] - 0s 923us/step - loss: 0.4752 - AUC: 0.8912 - binary_accuracy: 0.8180 - val_loss: 0.4662 - val_AUC: 0.8970 - val_binary_accuracy: 0.8281\n",
      "Epoch 173/200\n",
      "200/200 [==============================] - 0s 949us/step - loss: 0.4755 - AUC: 0.8909 - binary_accuracy: 0.8190 - val_loss: 0.4660 - val_AUC: 0.8970 - val_binary_accuracy: 0.8256\n",
      "Epoch 174/200\n",
      "200/200 [==============================] - 0s 883us/step - loss: 0.4753 - AUC: 0.8912 - binary_accuracy: 0.8203 - val_loss: 0.4662 - val_AUC: 0.8970 - val_binary_accuracy: 0.8244\n",
      "Epoch 175/200\n",
      "200/200 [==============================] - 0s 907us/step - loss: 0.4753 - AUC: 0.8910 - binary_accuracy: 0.8192 - val_loss: 0.4659 - val_AUC: 0.8971 - val_binary_accuracy: 0.8256\n",
      "Epoch 176/200\n",
      "200/200 [==============================] - 0s 944us/step - loss: 0.4753 - AUC: 0.8911 - binary_accuracy: 0.8191 - val_loss: 0.4661 - val_AUC: 0.8970 - val_binary_accuracy: 0.8244\n",
      "Epoch 177/200\n",
      "200/200 [==============================] - 0s 957us/step - loss: 0.4755 - AUC: 0.8909 - binary_accuracy: 0.8196 - val_loss: 0.4659 - val_AUC: 0.8972 - val_binary_accuracy: 0.8247\n",
      "Epoch 178/200\n",
      "200/200 [==============================] - 0s 933us/step - loss: 0.4752 - AUC: 0.8912 - binary_accuracy: 0.8192 - val_loss: 0.4659 - val_AUC: 0.8972 - val_binary_accuracy: 0.8231\n",
      "Epoch 1/200\n",
      "  2/200 [..............................] - ETA: 1:37 - loss: 0.8582 - AUC: 0.6178 - binary_accuracy: 0.6641WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.9762s). Check your callbacks.\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.7472 - AUC: 0.6742 - binary_accuracy: 0.6567 - val_loss: 0.6098 - val_AUC: 0.8250 - val_binary_accuracy: 0.7609\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5586 - AUC: 0.8638 - binary_accuracy: 0.7807 - val_loss: 0.5059 - val_AUC: 0.9000 - val_binary_accuracy: 0.8144\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4955 - AUC: 0.9004 - binary_accuracy: 0.8108 - val_loss: 0.4680 - val_AUC: 0.9161 - val_binary_accuracy: 0.8375\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 0s 861us/step - loss: 0.4667 - AUC: 0.9138 - binary_accuracy: 0.8283 - val_loss: 0.4477 - val_AUC: 0.9245 - val_binary_accuracy: 0.8462\n",
      "Epoch 5/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4493 - AUC: 0.9220 - binary_accuracy: 0.8387 - val_loss: 0.4358 - val_AUC: 0.9298 - val_binary_accuracy: 0.8547\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 0s 903us/step - loss: 0.4394 - AUC: 0.9258 - binary_accuracy: 0.8450 - val_loss: 0.4291 - val_AUC: 0.9324 - val_binary_accuracy: 0.8625\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 0s 1000us/step - loss: 0.4332 - AUC: 0.9286 - binary_accuracy: 0.8553 - val_loss: 0.4247 - val_AUC: 0.9339 - val_binary_accuracy: 0.8631\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 0s 918us/step - loss: 0.4288 - AUC: 0.9311 - binary_accuracy: 0.8627 - val_loss: 0.4210 - val_AUC: 0.9353 - val_binary_accuracy: 0.8747\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4257 - AUC: 0.9324 - binary_accuracy: 0.8687 - val_loss: 0.4187 - val_AUC: 0.9370 - val_binary_accuracy: 0.8809\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 0s 978us/step - loss: 0.4231 - AUC: 0.9340 - binary_accuracy: 0.8732 - val_loss: 0.4170 - val_AUC: 0.9380 - val_binary_accuracy: 0.8847\n",
      "Epoch 11/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4214 - AUC: 0.9351 - binary_accuracy: 0.8752 - val_loss: 0.4156 - val_AUC: 0.9390 - val_binary_accuracy: 0.8863\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4200 - AUC: 0.9360 - binary_accuracy: 0.8757 - val_loss: 0.4144 - val_AUC: 0.9391 - val_binary_accuracy: 0.8856\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4188 - AUC: 0.9367 - binary_accuracy: 0.8770 - val_loss: 0.4137 - val_AUC: 0.9399 - val_binary_accuracy: 0.8856\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 0s 856us/step - loss: 0.4179 - AUC: 0.9374 - binary_accuracy: 0.8798 - val_loss: 0.4131 - val_AUC: 0.9405 - val_binary_accuracy: 0.8822\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4171 - AUC: 0.9381 - binary_accuracy: 0.8801 - val_loss: 0.4124 - val_AUC: 0.9410 - val_binary_accuracy: 0.8869\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.4166 - AUC: 0.9383 - binary_accuracy: 0.8805 - val_loss: 0.4122 - val_AUC: 0.9414 - val_binary_accuracy: 0.8834\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 0s 883us/step - loss: 0.4161 - AUC: 0.9391 - binary_accuracy: 0.8822 - val_loss: 0.4119 - val_AUC: 0.9410 - val_binary_accuracy: 0.8825\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 0s 869us/step - loss: 0.4159 - AUC: 0.9391 - binary_accuracy: 0.8814 - val_loss: 0.4118 - val_AUC: 0.9415 - val_binary_accuracy: 0.8813\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 0s 868us/step - loss: 0.4154 - AUC: 0.9395 - binary_accuracy: 0.8818 - val_loss: 0.4117 - val_AUC: 0.9418 - val_binary_accuracy: 0.8838\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4151 - AUC: 0.9399 - binary_accuracy: 0.8814 - val_loss: 0.4114 - val_AUC: 0.9415 - val_binary_accuracy: 0.8800\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4149 - AUC: 0.9394 - binary_accuracy: 0.8809 - val_loss: 0.4115 - val_AUC: 0.9424 - val_binary_accuracy: 0.8841\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4147 - AUC: 0.9405 - binary_accuracy: 0.8813 - val_loss: 0.4107 - val_AUC: 0.9421 - val_binary_accuracy: 0.8834\n",
      "Epoch 23/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4146 - AUC: 0.9402 - binary_accuracy: 0.8805 - val_loss: 0.4110 - val_AUC: 0.9426 - val_binary_accuracy: 0.8838\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4145 - AUC: 0.9405 - binary_accuracy: 0.8813 - val_loss: 0.4104 - val_AUC: 0.9424 - val_binary_accuracy: 0.8841\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 0s 874us/step - loss: 0.4144 - AUC: 0.9403 - binary_accuracy: 0.8813 - val_loss: 0.4106 - val_AUC: 0.9428 - val_binary_accuracy: 0.8844\n",
      "Epoch 26/200\n",
      "200/200 [==============================] - 0s 988us/step - loss: 0.4142 - AUC: 0.9407 - binary_accuracy: 0.8819 - val_loss: 0.4107 - val_AUC: 0.9426 - val_binary_accuracy: 0.8822\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 0s 908us/step - loss: 0.4141 - AUC: 0.9410 - binary_accuracy: 0.8816 - val_loss: 0.4106 - val_AUC: 0.9429 - val_binary_accuracy: 0.8847\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 0s 838us/step - loss: 0.4142 - AUC: 0.9411 - binary_accuracy: 0.8813 - val_loss: 0.4106 - val_AUC: 0.9429 - val_binary_accuracy: 0.8834\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 0s 860us/step - loss: 0.4141 - AUC: 0.9409 - binary_accuracy: 0.8823 - val_loss: 0.4105 - val_AUC: 0.9432 - val_binary_accuracy: 0.8841\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 0s 862us/step - loss: 0.4141 - AUC: 0.9410 - binary_accuracy: 0.8808 - val_loss: 0.4107 - val_AUC: 0.9433 - val_binary_accuracy: 0.8819\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 0s 806us/step - loss: 0.4140 - AUC: 0.9413 - binary_accuracy: 0.8812 - val_loss: 0.4104 - val_AUC: 0.9434 - val_binary_accuracy: 0.8838\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 0s 835us/step - loss: 0.4139 - AUC: 0.9413 - binary_accuracy: 0.8825 - val_loss: 0.4104 - val_AUC: 0.9429 - val_binary_accuracy: 0.8819\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 0s 813us/step - loss: 0.4139 - AUC: 0.9412 - binary_accuracy: 0.8819 - val_loss: 0.4105 - val_AUC: 0.9432 - val_binary_accuracy: 0.8816\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 0s 853us/step - loss: 0.4139 - AUC: 0.9414 - binary_accuracy: 0.8823 - val_loss: 0.4105 - val_AUC: 0.9430 - val_binary_accuracy: 0.8813\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 0s 853us/step - loss: 0.4140 - AUC: 0.9413 - binary_accuracy: 0.8811 - val_loss: 0.4108 - val_AUC: 0.9431 - val_binary_accuracy: 0.8806\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 0s 853us/step - loss: 0.4138 - AUC: 0.9415 - binary_accuracy: 0.8812 - val_loss: 0.4104 - val_AUC: 0.9432 - val_binary_accuracy: 0.8816\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.4137 - AUC: 0.9413 - binary_accuracy: 0.8823 - val_loss: 0.4105 - val_AUC: 0.9433 - val_binary_accuracy: 0.8806\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 0s 838us/step - loss: 0.4139 - AUC: 0.9412 - binary_accuracy: 0.8816 - val_loss: 0.4108 - val_AUC: 0.9439 - val_binary_accuracy: 0.8800\n",
      "Epoch 39/200\n",
      "200/200 [==============================] - 0s 836us/step - loss: 0.4138 - AUC: 0.9414 - binary_accuracy: 0.8811 - val_loss: 0.4106 - val_AUC: 0.9438 - val_binary_accuracy: 0.8825\n",
      "Epoch 40/200\n",
      "200/200 [==============================] - 0s 825us/step - loss: 0.4137 - AUC: 0.9415 - binary_accuracy: 0.8822 - val_loss: 0.4107 - val_AUC: 0.9437 - val_binary_accuracy: 0.8838\n",
      "Epoch 41/200\n",
      "200/200 [==============================] - 0s 826us/step - loss: 0.4137 - AUC: 0.9417 - binary_accuracy: 0.8817 - val_loss: 0.4104 - val_AUC: 0.9434 - val_binary_accuracy: 0.8844\n",
      "Epoch 42/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.4137 - AUC: 0.9415 - binary_accuracy: 0.8810 - val_loss: 0.4106 - val_AUC: 0.9435 - val_binary_accuracy: 0.8825\n",
      "Epoch 43/200\n",
      "200/200 [==============================] - 0s 837us/step - loss: 0.4137 - AUC: 0.9416 - binary_accuracy: 0.8816 - val_loss: 0.4106 - val_AUC: 0.9435 - val_binary_accuracy: 0.8850\n",
      "Epoch 44/200\n",
      "200/200 [==============================] - 0s 839us/step - loss: 0.4136 - AUC: 0.9419 - binary_accuracy: 0.8827 - val_loss: 0.4109 - val_AUC: 0.9428 - val_binary_accuracy: 0.8791\n",
      "Epoch 45/200\n",
      "200/200 [==============================] - 0s 957us/step - loss: 0.4137 - AUC: 0.9414 - binary_accuracy: 0.8813 - val_loss: 0.4104 - val_AUC: 0.9438 - val_binary_accuracy: 0.8834\n",
      "Epoch 46/200\n",
      "200/200 [==============================] - 0s 823us/step - loss: 0.4136 - AUC: 0.9417 - binary_accuracy: 0.8812 - val_loss: 0.4106 - val_AUC: 0.9440 - val_binary_accuracy: 0.8816\n",
      "Epoch 47/200\n",
      "200/200 [==============================] - 0s 845us/step - loss: 0.4137 - AUC: 0.9417 - binary_accuracy: 0.8809 - val_loss: 0.4104 - val_AUC: 0.9437 - val_binary_accuracy: 0.8825\n",
      "Epoch 48/200\n",
      "200/200 [==============================] - 0s 813us/step - loss: 0.4137 - AUC: 0.9417 - binary_accuracy: 0.8817 - val_loss: 0.4106 - val_AUC: 0.9439 - val_binary_accuracy: 0.8816\n",
      "Epoch 49/200\n",
      "200/200 [==============================] - 0s 838us/step - loss: 0.4136 - AUC: 0.9420 - binary_accuracy: 0.8813 - val_loss: 0.4106 - val_AUC: 0.9435 - val_binary_accuracy: 0.8803\n",
      "Epoch 50/200\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.4150 - AUC: 0.9412 - binary_accuracy: 0.881 - 0s 1ms/step - loss: 0.4136 - AUC: 0.9417 - binary_accuracy: 0.8809 - val_loss: 0.4108 - val_AUC: 0.9432 - val_binary_accuracy: 0.8791\n",
      "Epoch 51/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4137 - AUC: 0.9416 - binary_accuracy: 0.8816 - val_loss: 0.4108 - val_AUC: 0.9440 - val_binary_accuracy: 0.8816\n",
      "Epoch 52/200\n",
      "200/200 [==============================] - 0s 980us/step - loss: 0.4136 - AUC: 0.9420 - binary_accuracy: 0.8816 - val_loss: 0.4106 - val_AUC: 0.9433 - val_binary_accuracy: 0.8803\n",
      "Epoch 53/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4136 - AUC: 0.9418 - binary_accuracy: 0.8812 - val_loss: 0.4104 - val_AUC: 0.9437 - val_binary_accuracy: 0.8816\n",
      "Epoch 54/200\n",
      "200/200 [==============================] - 0s 893us/step - loss: 0.4135 - AUC: 0.9421 - binary_accuracy: 0.8826 - val_loss: 0.4102 - val_AUC: 0.9435 - val_binary_accuracy: 0.8816\n",
      "Epoch 55/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4135 - AUC: 0.9418 - binary_accuracy: 0.8814 - val_loss: 0.4106 - val_AUC: 0.9437 - val_binary_accuracy: 0.8813\n",
      "Epoch 56/200\n",
      "200/200 [==============================] - 0s 947us/step - loss: 0.4134 - AUC: 0.9419 - binary_accuracy: 0.8817 - val_loss: 0.4108 - val_AUC: 0.9433 - val_binary_accuracy: 0.8828\n",
      "Epoch 57/200\n",
      "200/200 [==============================] - 0s 932us/step - loss: 0.4136 - AUC: 0.9417 - binary_accuracy: 0.8813 - val_loss: 0.4108 - val_AUC: 0.9443 - val_binary_accuracy: 0.8844\n",
      "Epoch 58/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4136 - AUC: 0.9418 - binary_accuracy: 0.8816 - val_loss: 0.4108 - val_AUC: 0.9440 - val_binary_accuracy: 0.8819\n",
      "Epoch 59/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4137 - AUC: 0.9418 - binary_accuracy: 0.8825 - val_loss: 0.4106 - val_AUC: 0.9440 - val_binary_accuracy: 0.8825\n",
      "Epoch 60/200\n",
      "200/200 [==============================] - 0s 919us/step - loss: 0.4136 - AUC: 0.9421 - binary_accuracy: 0.8820 - val_loss: 0.4104 - val_AUC: 0.9435 - val_binary_accuracy: 0.8800\n",
      "Epoch 61/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4136 - AUC: 0.9418 - binary_accuracy: 0.8813 - val_loss: 0.4105 - val_AUC: 0.9438 - val_binary_accuracy: 0.8803\n",
      "Epoch 62/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4136 - AUC: 0.9419 - binary_accuracy: 0.8810 - val_loss: 0.4105 - val_AUC: 0.9439 - val_binary_accuracy: 0.8822\n",
      "Epoch 63/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4136 - AUC: 0.9420 - binary_accuracy: 0.8809 - val_loss: 0.4105 - val_AUC: 0.9438 - val_binary_accuracy: 0.8844\n",
      "Epoch 64/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4135 - AUC: 0.9418 - binary_accuracy: 0.8812 - val_loss: 0.4111 - val_AUC: 0.9439 - val_binary_accuracy: 0.8800\n",
      "Epoch 65/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.4135 - AUC: 0.9419 - binary_accuracy: 0.8816 - val_loss: 0.4107 - val_AUC: 0.9439 - val_binary_accuracy: 0.8803\n",
      "Epoch 66/200\n",
      "200/200 [==============================] - 0s 987us/step - loss: 0.4136 - AUC: 0.9419 - binary_accuracy: 0.8815 - val_loss: 0.4109 - val_AUC: 0.9438 - val_binary_accuracy: 0.8819\n",
      "Epoch 67/200\n",
      "200/200 [==============================] - 0s 813us/step - loss: 0.4134 - AUC: 0.9421 - binary_accuracy: 0.8808 - val_loss: 0.4103 - val_AUC: 0.9438 - val_binary_accuracy: 0.8844\n",
      "Epoch 1/200\n",
      "  2/200 [..............................] - ETA: 2:13 - loss: 1.2151 - AUC: 0.2977 - binary_accuracy: 0.3750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 1.3452s). Check your callbacks.\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 1.1406 - AUC: 0.2723 - binary_accuracy: 0.3399 - val_loss: 1.0243 - val_AUC: 0.2993 - val_binary_accuracy: 0.3353\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 0s 990us/step - loss: 0.9187 - AUC: 0.3560 - binary_accuracy: 0.3708 - val_loss: 0.8425 - val_AUC: 0.4213 - val_binary_accuracy: 0.4606\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7773 - AUC: 0.5195 - binary_accuracy: 0.5384 - val_loss: 0.7274 - val_AUC: 0.6112 - val_binary_accuracy: 0.5934\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6880 - AUC: 0.6887 - binary_accuracy: 0.6516 - val_loss: 0.6517 - val_AUC: 0.7479 - val_binary_accuracy: 0.6938\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 968us/step - loss: 0.6264 - AUC: 0.7798 - binary_accuracy: 0.7192 - val_loss: 0.5984 - val_AUC: 0.8074 - val_binary_accuracy: 0.7516\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5825 - AUC: 0.8188 - binary_accuracy: 0.7548 - val_loss: 0.5604 - val_AUC: 0.8359 - val_binary_accuracy: 0.7769\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5520 - AUC: 0.8403 - binary_accuracy: 0.7770 - val_loss: 0.5341 - val_AUC: 0.8512 - val_binary_accuracy: 0.7969\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5320 - AUC: 0.8510 - binary_accuracy: 0.7877 - val_loss: 0.5167 - val_AUC: 0.8594 - val_binary_accuracy: 0.8053\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5194 - AUC: 0.8572 - binary_accuracy: 0.7917 - val_loss: 0.5058 - val_AUC: 0.8649 - val_binary_accuracy: 0.8097\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5118 - AUC: 0.8607 - binary_accuracy: 0.7942 - val_loss: 0.4992 - val_AUC: 0.8674 - val_binary_accuracy: 0.8116\n",
      "Epoch 11/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5071 - AUC: 0.8626 - binary_accuracy: 0.7953 - val_loss: 0.4951 - val_AUC: 0.8693 - val_binary_accuracy: 0.8141\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5042 - AUC: 0.8635 - binary_accuracy: 0.7960 - val_loss: 0.4926 - val_AUC: 0.8706 - val_binary_accuracy: 0.8144\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5022 - AUC: 0.8644 - binary_accuracy: 0.7966 - val_loss: 0.4909 - val_AUC: 0.8719 - val_binary_accuracy: 0.8153\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5007 - AUC: 0.8652 - binary_accuracy: 0.7978 - val_loss: 0.4896 - val_AUC: 0.8723 - val_binary_accuracy: 0.8163\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 0s 870us/step - loss: 0.4995 - AUC: 0.8654 - binary_accuracy: 0.7974 - val_loss: 0.4889 - val_AUC: 0.8736 - val_binary_accuracy: 0.8178\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4988 - AUC: 0.8661 - binary_accuracy: 0.7985 - val_loss: 0.4883 - val_AUC: 0.8740 - val_binary_accuracy: 0.8181\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4981 - AUC: 0.8665 - binary_accuracy: 0.7984 - val_loss: 0.4878 - val_AUC: 0.8739 - val_binary_accuracy: 0.8178\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4976 - AUC: 0.8667 - binary_accuracy: 0.7987 - val_loss: 0.4876 - val_AUC: 0.8748 - val_binary_accuracy: 0.8178\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4972 - AUC: 0.8669 - binary_accuracy: 0.7995 - val_loss: 0.4875 - val_AUC: 0.8745 - val_binary_accuracy: 0.8166\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4969 - AUC: 0.8668 - binary_accuracy: 0.7998 - val_loss: 0.4873 - val_AUC: 0.8750 - val_binary_accuracy: 0.8166\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4966 - AUC: 0.8672 - binary_accuracy: 0.7998 - val_loss: 0.4871 - val_AUC: 0.8751 - val_binary_accuracy: 0.8156\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 0.4965 - AUC: 0.8672 - binary_accuracy: 0.7995 - val_loss: 0.4870 - val_AUC: 0.8753 - val_binary_accuracy: 0.8169\n",
      "Epoch 23/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4963 - AUC: 0.8671 - binary_accuracy: 0.8002 - val_loss: 0.4869 - val_AUC: 0.8752 - val_binary_accuracy: 0.8156\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4960 - AUC: 0.8675 - binary_accuracy: 0.8004 - val_loss: 0.4867 - val_AUC: 0.8755 - val_binary_accuracy: 0.8156\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 0.4960 - AUC: 0.8672 - binary_accuracy: 0.7998 - val_loss: 0.4867 - val_AUC: 0.8753 - val_binary_accuracy: 0.8163\n",
      "Epoch 26/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 0.4960 - AUC: 0.8674 - binary_accuracy: 0.8007 - val_loss: 0.4866 - val_AUC: 0.8753 - val_binary_accuracy: 0.8163\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 0s 887us/step - loss: 0.4958 - AUC: 0.8673 - binary_accuracy: 0.8005 - val_loss: 0.4866 - val_AUC: 0.8755 - val_binary_accuracy: 0.8156\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 0s 851us/step - loss: 0.4958 - AUC: 0.8672 - binary_accuracy: 0.7998 - val_loss: 0.4864 - val_AUC: 0.8758 - val_binary_accuracy: 0.8169\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 0s 854us/step - loss: 0.4957 - AUC: 0.8676 - binary_accuracy: 0.7999 - val_loss: 0.4866 - val_AUC: 0.8752 - val_binary_accuracy: 0.8156\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 0s 922us/step - loss: 0.4957 - AUC: 0.8673 - binary_accuracy: 0.8005 - val_loss: 0.4865 - val_AUC: 0.8754 - val_binary_accuracy: 0.8159\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4957 - AUC: 0.8672 - binary_accuracy: 0.8002 - val_loss: 0.4865 - val_AUC: 0.8757 - val_binary_accuracy: 0.8163\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4956 - AUC: 0.8674 - binary_accuracy: 0.7998 - val_loss: 0.4865 - val_AUC: 0.8753 - val_binary_accuracy: 0.8156\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4956 - AUC: 0.8673 - binary_accuracy: 0.8009 - val_loss: 0.4866 - val_AUC: 0.8751 - val_binary_accuracy: 0.8153\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4955 - AUC: 0.8674 - binary_accuracy: 0.8000 - val_loss: 0.4865 - val_AUC: 0.8749 - val_binary_accuracy: 0.8153\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 0s 853us/step - loss: 0.4955 - AUC: 0.8673 - binary_accuracy: 0.8001 - val_loss: 0.4863 - val_AUC: 0.8752 - val_binary_accuracy: 0.8159\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4955 - AUC: 0.8675 - binary_accuracy: 0.8006 - val_loss: 0.4866 - val_AUC: 0.8748 - val_binary_accuracy: 0.8150\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 0s 997us/step - loss: 0.4954 - AUC: 0.8669 - binary_accuracy: 0.7998 - val_loss: 0.4865 - val_AUC: 0.8756 - val_binary_accuracy: 0.8156\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 0s 878us/step - loss: 0.4954 - AUC: 0.8676 - binary_accuracy: 0.8002 - val_loss: 0.4863 - val_AUC: 0.8751 - val_binary_accuracy: 0.8156\n",
      "Epoch 1/200\n",
      "  2/200 [..............................] - ETA: 1:36 - loss: 0.8549 - AUC: 0.4404 - binary_accuracy: 0.4609WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.9722s). Check your callbacks.\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.7871 - AUC: 0.5307 - binary_accuracy: 0.5308 - val_loss: 0.6797 - val_AUC: 0.7262 - val_binary_accuracy: 0.6666\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6239 - AUC: 0.8042 - binary_accuracy: 0.7280 - val_loss: 0.5705 - val_AUC: 0.8518 - val_binary_accuracy: 0.7769\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 0s 873us/step - loss: 0.5519 - AUC: 0.8538 - binary_accuracy: 0.7749 - val_loss: 0.5229 - val_AUC: 0.8698 - val_binary_accuracy: 0.7953\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5212 - AUC: 0.8648 - binary_accuracy: 0.7827 - val_loss: 0.5017 - val_AUC: 0.8779 - val_binary_accuracy: 0.8028\n",
      "Epoch 5/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5063 - AUC: 0.8711 - binary_accuracy: 0.7850 - val_loss: 0.4902 - val_AUC: 0.8816 - val_binary_accuracy: 0.8056\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4975 - AUC: 0.8745 - binary_accuracy: 0.7880 - val_loss: 0.4833 - val_AUC: 0.8849 - val_binary_accuracy: 0.8078\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 0s 947us/step - loss: 0.4918 - AUC: 0.8772 - binary_accuracy: 0.7897 - val_loss: 0.4789 - val_AUC: 0.8880 - val_binary_accuracy: 0.8112\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4880 - AUC: 0.8798 - binary_accuracy: 0.7912 - val_loss: 0.4756 - val_AUC: 0.8899 - val_binary_accuracy: 0.8122\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4851 - AUC: 0.8818 - binary_accuracy: 0.7916 - val_loss: 0.4730 - val_AUC: 0.8922 - val_binary_accuracy: 0.8131\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4825 - AUC: 0.8845 - binary_accuracy: 0.7959 - val_loss: 0.4707 - val_AUC: 0.8946 - val_binary_accuracy: 0.8172\n",
      "Epoch 11/200\n",
      "200/200 [==============================] - 0s 905us/step - loss: 0.4799 - AUC: 0.8878 - binary_accuracy: 0.7989 - val_loss: 0.4684 - val_AUC: 0.8980 - val_binary_accuracy: 0.8188\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 0s 982us/step - loss: 0.4772 - AUC: 0.8911 - binary_accuracy: 0.8028 - val_loss: 0.4658 - val_AUC: 0.9023 - val_binary_accuracy: 0.8216\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4744 - AUC: 0.8947 - binary_accuracy: 0.8084 - val_loss: 0.4635 - val_AUC: 0.9060 - val_binary_accuracy: 0.8269\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.4716 - AUC: 0.8992 - binary_accuracy: 0.8126 - val_loss: 0.4609 - val_AUC: 0.9092 - val_binary_accuracy: 0.8278\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 0s 882us/step - loss: 0.4689 - AUC: 0.9025 - binary_accuracy: 0.8164 - val_loss: 0.4592 - val_AUC: 0.9129 - val_binary_accuracy: 0.8341\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 0s 962us/step - loss: 0.4666 - AUC: 0.9066 - binary_accuracy: 0.8220 - val_loss: 0.4576 - val_AUC: 0.9160 - val_binary_accuracy: 0.8366\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 0s 967us/step - loss: 0.4647 - AUC: 0.9094 - binary_accuracy: 0.8263 - val_loss: 0.4563 - val_AUC: 0.9188 - val_binary_accuracy: 0.8391\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4632 - AUC: 0.9116 - binary_accuracy: 0.8279 - val_loss: 0.4552 - val_AUC: 0.9202 - val_binary_accuracy: 0.8441\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4621 - AUC: 0.9137 - binary_accuracy: 0.8325 - val_loss: 0.4543 - val_AUC: 0.9222 - val_binary_accuracy: 0.8466\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4611 - AUC: 0.9154 - binary_accuracy: 0.8349 - val_loss: 0.4538 - val_AUC: 0.9234 - val_binary_accuracy: 0.8462\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 0s 903us/step - loss: 0.4601 - AUC: 0.9169 - binary_accuracy: 0.8366 - val_loss: 0.4529 - val_AUC: 0.9245 - val_binary_accuracy: 0.8484\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 0s 854us/step - loss: 0.4595 - AUC: 0.9184 - binary_accuracy: 0.8377 - val_loss: 0.4523 - val_AUC: 0.9252 - val_binary_accuracy: 0.8509\n",
      "Epoch 23/200\n",
      "200/200 [==============================] - 0s 823us/step - loss: 0.4587 - AUC: 0.9196 - binary_accuracy: 0.8405 - val_loss: 0.4519 - val_AUC: 0.9264 - val_binary_accuracy: 0.8509\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 0s 843us/step - loss: 0.4580 - AUC: 0.9210 - binary_accuracy: 0.8417 - val_loss: 0.4511 - val_AUC: 0.9269 - val_binary_accuracy: 0.8531\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.4571 - AUC: 0.9218 - binary_accuracy: 0.8445 - val_loss: 0.4508 - val_AUC: 0.9285 - val_binary_accuracy: 0.8550\n",
      "Epoch 26/200\n",
      "200/200 [==============================] - 0s 907us/step - loss: 0.4565 - AUC: 0.9231 - binary_accuracy: 0.8460 - val_loss: 0.4502 - val_AUC: 0.9291 - val_binary_accuracy: 0.8559\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 0s 858us/step - loss: 0.4558 - AUC: 0.9243 - binary_accuracy: 0.8453 - val_loss: 0.4496 - val_AUC: 0.9298 - val_binary_accuracy: 0.8584\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 0s 868us/step - loss: 0.4551 - AUC: 0.9254 - binary_accuracy: 0.8487 - val_loss: 0.4489 - val_AUC: 0.9311 - val_binary_accuracy: 0.8600\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 0s 863us/step - loss: 0.4544 - AUC: 0.9263 - binary_accuracy: 0.8489 - val_loss: 0.4487 - val_AUC: 0.9328 - val_binary_accuracy: 0.8637\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 0s 883us/step - loss: 0.4537 - AUC: 0.9282 - binary_accuracy: 0.8512 - val_loss: 0.4478 - val_AUC: 0.9324 - val_binary_accuracy: 0.8631\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 0s 873us/step - loss: 0.4532 - AUC: 0.9284 - binary_accuracy: 0.8543 - val_loss: 0.4475 - val_AUC: 0.9338 - val_binary_accuracy: 0.8659\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 0s 888us/step - loss: 0.4527 - AUC: 0.9295 - binary_accuracy: 0.8559 - val_loss: 0.4475 - val_AUC: 0.9344 - val_binary_accuracy: 0.8684\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4522 - AUC: 0.9308 - binary_accuracy: 0.8570 - val_loss: 0.4468 - val_AUC: 0.9352 - val_binary_accuracy: 0.8697\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4519 - AUC: 0.9310 - binary_accuracy: 0.8582 - val_loss: 0.4466 - val_AUC: 0.9359 - val_binary_accuracy: 0.8687\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 0s 992us/step - loss: 0.4517 - AUC: 0.9321 - binary_accuracy: 0.8584 - val_loss: 0.4465 - val_AUC: 0.9368 - val_binary_accuracy: 0.8712\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4514 - AUC: 0.9327 - binary_accuracy: 0.8607 - val_loss: 0.4466 - val_AUC: 0.9367 - val_binary_accuracy: 0.8681\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 0s 866us/step - loss: 0.4511 - AUC: 0.9333 - binary_accuracy: 0.8620 - val_loss: 0.4463 - val_AUC: 0.9372 - val_binary_accuracy: 0.8675\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 0s 996us/step - loss: 0.4511 - AUC: 0.9334 - binary_accuracy: 0.8614 - val_loss: 0.4461 - val_AUC: 0.9382 - val_binary_accuracy: 0.8756\n",
      "Epoch 39/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4508 - AUC: 0.9344 - binary_accuracy: 0.8644 - val_loss: 0.4464 - val_AUC: 0.9384 - val_binary_accuracy: 0.8703\n",
      "Epoch 40/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4508 - AUC: 0.9346 - binary_accuracy: 0.8638 - val_loss: 0.4459 - val_AUC: 0.9379 - val_binary_accuracy: 0.8722\n",
      "Epoch 41/200\n",
      "200/200 [==============================] - 0s 917us/step - loss: 0.4506 - AUC: 0.9345 - binary_accuracy: 0.8644 - val_loss: 0.4464 - val_AUC: 0.9389 - val_binary_accuracy: 0.8759\n",
      "Epoch 42/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4506 - AUC: 0.9354 - binary_accuracy: 0.8648 - val_loss: 0.4458 - val_AUC: 0.9389 - val_binary_accuracy: 0.8769\n",
      "Epoch 43/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4507 - AUC: 0.9352 - binary_accuracy: 0.8672 - val_loss: 0.4458 - val_AUC: 0.9394 - val_binary_accuracy: 0.8759\n",
      "Epoch 44/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4504 - AUC: 0.9362 - binary_accuracy: 0.8673 - val_loss: 0.4456 - val_AUC: 0.9389 - val_binary_accuracy: 0.8747\n",
      "Epoch 45/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.4503 - AUC: 0.9359 - binary_accuracy: 0.8677 - val_loss: 0.4458 - val_AUC: 0.9391 - val_binary_accuracy: 0.8719\n",
      "Epoch 46/200\n",
      "200/200 [==============================] - 0s 821us/step - loss: 0.4504 - AUC: 0.9359 - binary_accuracy: 0.8659 - val_loss: 0.4458 - val_AUC: 0.9395 - val_binary_accuracy: 0.8766\n",
      "Epoch 47/200\n",
      "200/200 [==============================] - 0s 944us/step - loss: 0.4504 - AUC: 0.9360 - binary_accuracy: 0.8683 - val_loss: 0.4459 - val_AUC: 0.9403 - val_binary_accuracy: 0.8769\n",
      "Epoch 48/200\n",
      "200/200 [==============================] - 0s 892us/step - loss: 0.4502 - AUC: 0.9363 - binary_accuracy: 0.8662 - val_loss: 0.4455 - val_AUC: 0.9403 - val_binary_accuracy: 0.8797\n",
      "Epoch 49/200\n",
      "200/200 [==============================] - 0s 849us/step - loss: 0.4502 - AUC: 0.9361 - binary_accuracy: 0.8668 - val_loss: 0.4459 - val_AUC: 0.9406 - val_binary_accuracy: 0.8794\n",
      "Epoch 50/200\n",
      "200/200 [==============================] - 0s 896us/step - loss: 0.4503 - AUC: 0.9367 - binary_accuracy: 0.8685 - val_loss: 0.4455 - val_AUC: 0.9402 - val_binary_accuracy: 0.8794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "200/200 [==============================] - 0s 825us/step - loss: 0.4504 - AUC: 0.9366 - binary_accuracy: 0.8690 - val_loss: 0.4456 - val_AUC: 0.9405 - val_binary_accuracy: 0.8797\n",
      "Epoch 52/200\n",
      "200/200 [==============================] - 0s 888us/step - loss: 0.4502 - AUC: 0.9365 - binary_accuracy: 0.8683 - val_loss: 0.4455 - val_AUC: 0.9404 - val_binary_accuracy: 0.8794\n",
      "Epoch 53/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4502 - AUC: 0.9370 - binary_accuracy: 0.8684 - val_loss: 0.4454 - val_AUC: 0.9400 - val_binary_accuracy: 0.8781\n",
      "Epoch 54/200\n",
      "200/200 [==============================] - 0s 933us/step - loss: 0.4503 - AUC: 0.9368 - binary_accuracy: 0.8687 - val_loss: 0.4456 - val_AUC: 0.9404 - val_binary_accuracy: 0.8794\n",
      "Epoch 55/200\n",
      "200/200 [==============================] - 0s 918us/step - loss: 0.4501 - AUC: 0.9366 - binary_accuracy: 0.8690 - val_loss: 0.4456 - val_AUC: 0.9410 - val_binary_accuracy: 0.8806\n",
      "Epoch 56/200\n",
      " 82/200 [===========>..................] - ETA: 0s - loss: 0.4516 - AUC: 0.9375 - binary_accuracy: 0.8704"
     ]
    }
   ],
   "source": [
    "# hidden_sizes = [2, 5, 10, 20, 50]\n",
    "# l2_regs = [0.01, 0.001, 0.0001]\n",
    "# activations = ['relu', 'tanh']\n",
    "\n",
    "hidden_sizes = [2, 5]\n",
    "l2_regs = [0.01]\n",
    "activations = ['relu', 'tanh']\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', mode='max', patience=10, restore_best_weights=True)\n",
    "\n",
    "for activation in activations:\n",
    "    for l2_reg in l2_regs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            if activation == 'relu':\n",
    "                activate = tf.keras.activations.relu\n",
    "            elif activation == 'tanh':\n",
    "                activate = tf.keras.activations.tanh\n",
    "\n",
    "            # Create Tensorboard Callback\n",
    "            param_string = 'act-{},l2-{},hs-{}'.format(activation, l2_reg, hidden_size)\n",
    "            log_dir = 'logs/binary_classification_test/' + param_string\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "            # Input layer\n",
    "            inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "\n",
    "            # Hidden layer with regularization and ReLU\n",
    "            hidden = tf.keras.layers.Dense(hidden_size, kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs)\n",
    "            hidden = activate(hidden)\n",
    "\n",
    "            # Output layer with regularization and sigmoid\n",
    "            outputs = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(hidden)\n",
    "            outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=outputs, name='RegularizedModel')\n",
    "\n",
    "            model.compile(\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    loss=tf.losses.BinaryCrossentropy(),\n",
    "                    metrics=[tf.keras.metrics.AUC(name='AUC'), tf.keras.metrics.BinaryAccuracy()],\n",
    "            )\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                      validation_data=(X_dev, y_dev),\n",
    "                      callbacks=[early_call, tensorboard_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
